{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initailization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = {\n",
    "    \"macro_area_ratio\": \"the ratio of total macros area in the layout\",\n",
    "    \"mean_macro_edge_length\": \"the edge length of all macros calculated by average\",\n",
    "    \"mean_macro_neighbor_distance\": \"the total near distances of macros calculated by average\",\n",
    "    \"min_rudy\": \"the minimum value of the rudy map\",\n",
    "    \"max_rudy\": \"the maximum value of the rudy map\",\n",
    "    \"mean_rudy\": \"the average of the rudy map\",\n",
    "    \"std_rudy\": \"the standard deviation of the rudy map\",\n",
    "    \"PAR_rudy\": \"the Peak-to-Average Ratio of the rudy map\",\n",
    "    \"high_density_rudy_ratio\": \"the ratio of hotspots area in the rudy map\",\n",
    "    \"min_rudy_pin\": \"the minimum value of the rudy pin map\",\n",
    "    \"max_rudy_pin\": \"the maximum value of the rudy pin map\",\n",
    "    \"mean_rudy_pin\": \"the average of the rudy pin map\",\n",
    "    \"std_rudy_pin\": \"the standard deviation of the rudy pin map\",\n",
    "    \"PAR_rudy_pin\": \"the Peak-to-Average Ratio of the rudy pin map\",\n",
    "    \"high_density_rudy_pin_ratio\": \"the ratio of hotspots area in the rudy pin map\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_func_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_design = [\"RISCY-a\", \"RISCY-b\", \"RISCY-FPU-a\", \"RISCY-FPU-b\"]\n",
    "test_design_a = [\"zero-riscy-a\"]\n",
    "test_design_b = [\"zero-riscy-b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"sk-your_api_key_here\"\n",
    "\n",
    "def encode_image(features):\n",
    "    features_b64 = []\n",
    "    for image in features:\n",
    "        buff = BytesIO()\n",
    "        image.save(buff, format=\"PNG\")\n",
    "        buff.seek(0)\n",
    "        image_b64 = base64.b64encode(buff.read()).decode()\n",
    "        features_b64.append(image_b64)\n",
    "    return features_b64\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPDL(\n",
       "  (encoder): Encoder(\n",
       "    (c1): conv(\n",
       "      (main): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (c2): conv(\n",
       "      (main): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (c3): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv1): conv(\n",
       "      (main): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (upc1): upconv(\n",
       "      (main): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): conv(\n",
       "      (main): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (upc2): upconv(\n",
       "      (main): Sequential(\n",
       "        (0): ConvTranspose2d(48, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models\n",
    "device = \"cuda:4\"\n",
    "opt = {'task': 'congestion_gpdl', 'save_path': 'work_dir/congestion_gpdl/', 'pretrained': '/home/felixchaotw/CircuitNet/model/model_iters_20000.pth', 'max_iters': 200000, 'plot_roc': False, 'arg_file': None, 'cpu': False, 'dataroot': '../../training_set/congestion', 'ann_file_train': './files/train_N28.csv', 'ann_file_test': './files/test_N28.csv', 'dataset_type': 'CongestionDataset', 'batch_size': 16, 'aug_pipeline': ['Flip'], 'model_type': 'GPDL', 'in_channels': 3, 'out_channels': 1, 'lr': 0.0002, 'weight_decay': 0, 'loss_type': 'MSELoss', 'eval_metric': ['NRMS', 'SSIM', 'EMD'], 'ann_file': './files/test_N28.csv', 'test_mode': True}\n",
    "model = models.__dict__[\"GPDL\"](**opt)\n",
    "model.init_weights(**opt)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15229852198689037\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests, base64\n",
    "import json\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import heapq\n",
    "\n",
    "tile_size = 16\n",
    "image_size = 256\n",
    "\n",
    "\n",
    "def get_tiles_congestion(image_array):\n",
    "    tiles = []\n",
    "    for x in range(0, image_size, tile_size):\n",
    "        for y in range(0, image_size, tile_size):\n",
    "            tile = image_array[x:x+tile_size, y:y+tile_size]\n",
    "            tiles.append(np.mean(tile))\n",
    "            \n",
    "    tiles = heapq.nlargest(20, tiles)\n",
    "    return tiles\n",
    "\n",
    "file_path = '/data2/NVIDIA/CircuitNet-N28/Dataset/congestion/feature/zero-riscy-b/10176-zero-riscy-b-3-c5-u0.75-m1-p5-f1.npy'\n",
    "label_path = '/data2/NVIDIA/CircuitNet-N28/Dataset/congestion/label/zero-riscy-b/10176-zero-riscy-b-3-c5-u0.75-m1-p5-f1.npy'\n",
    "numpy_image = np.load(file_path)\n",
    "label_image = np.load(label_path).squeeze()\n",
    "batch_image = numpy_image.transpose(2,0,1)\n",
    "image_features = []\n",
    "image_inferences = []\n",
    "\n",
    "for i, image in enumerate(batch_image):\n",
    "    image_features.append(image)\n",
    "    image_inferences.append(Image.fromarray(np.uint8(image * 255)))\n",
    "    \n",
    "tiles = get_tiles_congestion(label_image)\n",
    "image_inferences.append(Image.fromarray(np.uint8(label_image * 255)))\n",
    "print(np.mean(tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_images = encode_image(image_inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_features(image):\n",
    "    tiles_size = 2.25\n",
    "    image_height, image_width = image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    image = np.uint8(image*255)\n",
    "    \n",
    "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    centroids = []\n",
    "    total_macros_area = 0\n",
    "    total_edge_length = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        total_macros_area += w * h\n",
    "        total_edge_length += 2 * (w + h)\n",
    "        centroid_x = x + w / 2\n",
    "        centroid_y = y + h / 2\n",
    "        centroids.append((centroid_x, centroid_y))\n",
    "    \n",
    "    neighbor_distances = []\n",
    "    for i, (x1, y1) in enumerate(centroids):\n",
    "        min_distance = float(\"inf\")  \n",
    "        for j, (x2, y2) in enumerate(centroids):\n",
    "            if i != j: \n",
    "                distance = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "        neighbor_distances.append(min_distance)\n",
    "    \n",
    "\n",
    "    if neighbor_distances and num_macros > 1:\n",
    "        mean_neighbor_distance = sum(neighbor_distances) / len(neighbor_distances)\n",
    "    else:\n",
    "        mean_neighbor_distance = 0.0\n",
    " \n",
    "    \n",
    "    return {\n",
    "            \"mean_macro_neighbor_distance\": float(mean_neighbor_distance * tiles_size),\n",
    "            \"macro_area_ratio\": total_macros_area / total_image_area,\n",
    "            \"mean_macro_edge_length\": (total_edge_length / num_macros) * tiles_size,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rudy_features(image):\n",
    "    total_area = image.shape[0] * image.shape[1]\n",
    "    max_rudy = np.max(image)\n",
    "    min_rudy = np.min(image)\n",
    "    mean_rudy = np.mean(image)\n",
    "    std_rudy = np.std(image)\n",
    "    par_rudy = max_rudy / mean_rudy\n",
    "    high_density_rudy_ratio = (image > mean_rudy).sum() /  total_area\n",
    "    \n",
    "    return {\n",
    "        \"mean_rudy\": mean_rudy,\n",
    "        \"std_rudy\": std_rudy,\n",
    "        \"PAR_rudy\": par_rudy,\n",
    "        \"high_density_rudy_ratio\": high_density_rudy_ratio,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rudy_pin_features(image):\n",
    "    total_area = image.shape[0] * image.shape[1]\n",
    "    max_rudy = np.max(image)\n",
    "    min_rudy = np.min(image)\n",
    "    mean_rudy = np.mean(image)\n",
    "    std_rudy = np.std(image)\n",
    "    par_rudy = max_rudy / mean_rudy\n",
    "    high_density_rudy_ratio = (image > mean_rudy).sum() /  total_area\n",
    "    \n",
    "    return {\n",
    "        \"mean_rudy_pin\": mean_rudy,\n",
    "        \"std_rudy_pin\": std_rudy,\n",
    "        \"PAR_rudy_pin\": par_rudy,\n",
    "        \"high_density_rudy_pin_ratio\": high_density_rudy_ratio,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(images):\n",
    "    macro_feature = images[0]\n",
    "    rudy_feature = images[1]\n",
    "    rudy_pin_feature = images[2]\n",
    "    \n",
    "    mf = macro_features(macro_feature)\n",
    "    rf = rudy_features(rudy_feature)\n",
    "    rpf = rudy_pin_features(rudy_pin_feature)\n",
    "    \n",
    "    final_features = {**mf, **rf, **rpf}\n",
    "    \n",
    "    for feat_func in feat_func_list:\n",
    "        feat = feat_func(images)\n",
    "        final_features.update(feat)\n",
    "        \n",
    "    return final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_macro_neighbor_distance': 86.29562503334292,\n",
       " 'macro_area_ratio': 0.5718231201171875,\n",
       " 'mean_macro_edge_length': 392.7,\n",
       " 'mean_rudy': np.float64(0.16759109363739882),\n",
       " 'std_rudy': np.float64(0.10180513027100063),\n",
       " 'PAR_rudy': np.float64(5.966904196971269),\n",
       " 'high_density_rudy_ratio': np.float64(0.4022674560546875),\n",
       " 'mean_rudy_pin': np.float64(0.0994746065198448),\n",
       " 'std_rudy_pin': np.float64(0.07769547824745768),\n",
       " 'PAR_rudy_pin': np.float64(10.052816844271748),\n",
       " 'high_density_rudy_pin_ratio': np.float64(0.1454620361328125),\n",
       " 'macro_spacing_std': np.float64(123.73596989365004),\n",
       " 'macro_boundary_distance_var': np.float64(24077.164218750004),\n",
       " 'pin_clustering_factor': np.float64(1.74778133797246e-05),\n",
       " 'macro_diagonal_connectivity': np.float64(203264.4375),\n",
       " 'rudy_gradation_smoothness': np.float64(0.09569972731248028),\n",
       " 'macro_edge_proximity_to_pins': 139.5,\n",
       " 'macro_cluster_compactness': 14.37886962195726,\n",
       " 'pin_density_variance': np.float64(0.003624759987305908),\n",
       " 'pin_neighborhood_uniformity': np.float64(-15.549918283474963),\n",
       " 'rudy_consistency_index': np.float64(0.6074614590872405),\n",
       " 'pin_to_macro_rudy_gradient_proximity': np.float64(1968.1680614585962),\n",
       " 'sector_rudy_disparity': np.float64(0.1307015893183441),\n",
       " 'macro_corner_count': 60,\n",
       " 'pin_to_macro_edge_proximity_std': np.float32(13.988997),\n",
       " 'macro_linear_alignment': 0.6,\n",
       " 'rudy_peak_clustering': np.float64(0.009346961975097656),\n",
       " 'macro_pin_alignment_score': 81.0,\n",
       " 'pin_density_gradient': np.float64(9870.882636400103),\n",
       " 'macro_to_pin_cluster_proximity': np.float64(268.57551530714795)}"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_features(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "def dataset_setting(designs):\n",
    "    df_list = []\n",
    "    for design in designs:\n",
    "        feature_path = f\"/data2/NVIDIA/CircuitNet-N28/Dataset/congestion/feature/{design}/\" \n",
    "        label_path = f\"/data2/NVIDIA/CircuitNet-N28/Dataset/congestion/label/{design}/\"\n",
    "\n",
    "        labels = []\n",
    "        ids = []\n",
    "\n",
    "        for filename in tqdm(os.listdir(label_path)):\n",
    "            file_path = os.path.join(label_path, filename)\n",
    "            label_image = np.load(file_path).squeeze()\n",
    "            label = float(np.mean(get_tiles_congestion(label_image)))\n",
    "            ids.append(filename)\n",
    "            labels.append(label)\n",
    "            \n",
    "        df = pd.DataFrame({\"id\": ids,})\n",
    "\n",
    "        for filename in tqdm(os.listdir(feature_path)):\n",
    "            file_path = os.path.join(feature_path, filename)\n",
    "            numpy_image = np.load(file_path)\n",
    "            batch_image = numpy_image.transpose(2,0,1)\n",
    "            image_features = []\n",
    "            for i, image in enumerate(batch_image):\n",
    "                image_features.append(image)\n",
    "            \n",
    "            index = (df[\"id\"] == filename)\n",
    "            \n",
    "            all_features = get_all_features(image_features)\n",
    "            for key, value in all_features.items():\n",
    "                df.loc[index, key] = value\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                input_image = torch.tensor(batch_image).unsqueeze(0).float().to(device)\n",
    "                output_image = model(input_image)\n",
    "                prediction = np.mean(get_tiles_congestion(output_image.cpu().numpy().squeeze()))\n",
    "            \n",
    "            df.loc[index, \"prediction_gpdl\"] = prediction\n",
    "        \n",
    "        df['label'] = labels\n",
    "        df_list.append(df)\n",
    "        \n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2003/2003 [00:04<00:00, 465.55it/s]\n",
      "100%|██████████| 2003/2003 [01:49<00:00, 18.34it/s]\n",
      "100%|██████████| 1858/1858 [00:04<00:00, 435.88it/s]\n",
      "100%|██████████| 1858/1858 [02:04<00:00, 14.93it/s]\n",
      "100%|██████████| 1969/1969 [00:04<00:00, 472.20it/s]\n",
      "100%|██████████| 1969/1969 [01:48<00:00, 18.13it/s]\n",
      "100%|██████████| 1248/1248 [00:02<00:00, 434.05it/s]\n",
      "100%|██████████| 1248/1248 [01:24<00:00, 14.85it/s]\n",
      "100%|██████████| 2042/2042 [00:04<00:00, 506.11it/s]\n",
      "100%|██████████| 2042/2042 [01:38<00:00, 20.77it/s]\n",
      "100%|██████████| 1122/1122 [00:02<00:00, 493.49it/s]\n",
      "100%|██████████| 1122/1122 [01:05<00:00, 17.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = dataset_setting(train_design)\n",
    "test_df_a = dataset_setting(test_design_a)\n",
    "test_df_b = dataset_setting(test_design_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[list(feat_pool.keys()) + [\"id\", \"label\", \"prediction_gpdl\"] + list(new_feat_pool.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_a = test_df_a[list(feat_pool.keys()) + [\"id\", \"label\", \"prediction_gpdl\"] + list(new_feat_pool.keys())]\n",
    "test_df_b = test_df_b[list(feat_pool.keys()) + [\"id\", \"label\", \"prediction_gpdl\"] + list(new_feat_pool.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, n_estimators=1000, random_state=18)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=10, n_estimators=1000, random_state=18)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_estimators=1000, random_state=18)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = train_df.drop(columns=[\"id\", \"label\", \"prediction_gpdl\"])\n",
    "y = train_df[\"label\"]\n",
    "regressor = RandomForestRegressor(random_state=18, max_depth=10, n_estimators=1000)\n",
    "regressor.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature')"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = regressor.feature_importances_ \n",
    "sorted_idx = np.argsort(feature_importance) # Sort index on feature importance\n",
    "fig = plt.figure(figsize=(20, 15)) # Set plot size (denoted in inches)\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(x.columns)[sorted_idx])\n",
    "\n",
    "plt.xlabel(\"Feature importance\") # Add x axis\n",
    "plt.ylabel(\"Feature\") # Add y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_a = regressor.predict(test_df_a.drop(columns=[\"id\", \"label\", \"prediction_gpdl\"]))\n",
    "y_hat_b = regressor.predict(test_df_b.drop(columns=[\"id\", \"label\", \"prediction_gpdl\"]))\n",
    "test_df_a[\"prediction\"] = y_hat_a\n",
    "test_df_b[\"prediction\"] = y_hat_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def evalute_corr(congestion_set, predicted, corr_metrics):\n",
    "    x = np.array(list(congestion_set.values()))\n",
    "    predicted = sorted(predicted.items(), key=lambda x: x[1])\n",
    "    y = np.array([congestion_set[file_path] for file_path, _ in predicted])\n",
    "    results = {}\n",
    "    if \"PLCC\" in corr_metrics:\n",
    "        results[\"PLCC\"] = stats.pearsonr(x, y)\n",
    "    if \"SRCC\" in corr_metrics:\n",
    "        results[\"SRCC\"] = stats.spearmanr(x, y)\n",
    "    if \"KRCC\" in corr_metrics:\n",
    "        results[\"KRCC\"] = stats.kendalltau(x, y)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def evalute_ndcg(congestion_set, predicted):\n",
    "    congestion_set = dict(sorted(congestion_set.items(), key=lambda x: x[0]))\n",
    "    x = np.array(list(congestion_set.values()))\n",
    "    predicted = dict(sorted(predicted.items(), key=lambda x: x[0]))\n",
    "    y = np.array(list(predicted.values()))\n",
    "    return ndcg_score([x], [y])\n",
    "\n",
    "def evaluate_design(df):\n",
    "    congestion_set = dict(zip(df[\"id\"], df[\"label\"]))\n",
    "    congestion_set = dict(sorted(congestion_set.items(), key=lambda x: x[1]))\n",
    "    predicted = dict(zip(df[\"id\"], df[\"prediction\"]))\n",
    "    corr_metrics = [\"PLCC\", \"SRCC\", \"KRCC\"]\n",
    "    results = evalute_corr(congestion_set, predicted, corr_metrics)\n",
    "    results[\"NDCG\"] = evalute_ndcg(congestion_set, predicted)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.1440677872814935), pvalue=np.float64(6.136830228930175e-11)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.12987480849087346), pvalue=np.float64(3.85691144235756e-09)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.08753846973362364), pvalue=np.float64(3.0610691006664493e-09)),\n",
       " 'NDCG': np.float64(0.9597174164328586)}"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.16684860167978002), pvalue=np.float64(1.8872803874000822e-08)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.1477557449373694), pvalue=np.float64(6.658853690113137e-07)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09888424987077021), pvalue=np.float64(7.070526596401339e-07)),\n",
       " 'NDCG': np.float64(0.9551973836885712)}"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.1424852398497009), pvalue=np.float64(9.945575098189869e-11)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.13780563123250592), pvalue=np.float64(4.0194304338346045e-10)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09319549415221656), pvalue=np.float64(2.765316358453054e-10)),\n",
       " 'NDCG': np.float64(0.9575622155797455)}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.13055921604252813), pvalue=np.float64(1.1483890112034805e-05)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.14136396322915543), pvalue=np.float64(1.9964976128417005e-06)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09295319893435126), pvalue=np.float64(3.1322436170843306e-06)),\n",
       " 'NDCG': np.float64(0.9574970061843386)}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.08649899869908996), pvalue=np.float64(9.089138708955547e-05)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.10799761174978338), pvalue=np.float64(1.0003287664675104e-06)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.07199844897328461), pvalue=np.float64(1.0832094471205787e-06)),\n",
       " 'NDCG': np.float64(0.9508102811104201)}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.08106242004339176), pvalue=np.float64(0.006592959389750979)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.11006563989064824), pvalue=np.float64(0.000220834804209146)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.07120124060598831), pvalue=np.float64(0.00035560792871340764)),\n",
       " 'NDCG': np.float64(0.9482617711615231)}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.11492179864327486), pvalue=np.float64(1.916871082641949e-07)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.116263773716575), pvalue=np.float64(1.3758572029735668e-07)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.07841515015253522), pvalue=np.float64(1.0936155507802135e-07)),\n",
       " 'NDCG': np.float64(0.955547269301174)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.06048239918794246), pvalue=np.float64(0.04281286941589542)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.061217035918441604), pvalue=np.float64(0.040346903394361935)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.03749811125690882), pvalue=np.float64(0.060016677368795415)),\n",
       " 'NDCG': np.float64(0.9472215029079386)}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.12158221019419038), pvalue=np.float64(3.5637685823571776e-08)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.11457699520995515), pvalue=np.float64(2.0861072522749311e-07)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.077171737337081), pvalue=np.float64(1.7299893953532764e-07)),\n",
       " 'NDCG': np.float64(0.9548941753877704)}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.01249986266233186), pvalue=np.float64(0.6757655188126636)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.002552243052909621), pvalue=np.float64(0.9319469983138495)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.000795260248916458), pvalue=np.float64(0.9681845807460547)),\n",
       " 'NDCG': np.float64(0.9436568898751014)}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.15332523936835998), pvalue=np.float64(3.2719845822531e-12)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.14705771411352941), pvalue=np.float64(2.4291706363333866e-11)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09901616340680715), pvalue=np.float64(2.006040679788891e-11)),\n",
       " 'NDCG': np.float64(0.9545436011844779)}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.011194661762888136), pvalue=np.float64(0.7079779371274357)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.029953475191777913), pvalue=np.float64(0.3161329629873302)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.019471151934470556), pvalue=np.float64(0.32879130137346946)),\n",
       " 'NDCG': np.float64(0.9430314091296831)}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.18486151442154536), pvalue=np.float64(3.7271822723408365e-17)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.1729146389525253), pvalue=np.float64(3.594757361317978e-15)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.11712939123641111), pvalue=np.float64(2.15212887455019e-15)),\n",
       " 'NDCG': np.float64(0.9590013777522316)}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.0025506423330742415), pvalue=np.float64(0.9319895764896465)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.0033173624686513646), pvalue=np.float64(0.9116197488602444)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.0016923138096942225), pvalue=np.float64(0.9323600583851215)),\n",
       " 'NDCG': np.float64(0.9443737844944227)}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.14887139981342434), pvalue=np.float64(1.3717363391472461e-11)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.13808540919669185), pvalue=np.float64(3.7022694791263173e-10)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09325116219026855), pvalue=np.float64(2.6987369793501594e-10)),\n",
       " 'NDCG': np.float64(0.9578952759802737)}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.03558043756108483), pvalue=np.float64(0.2337083550504899)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.026187246630589186), pvalue=np.float64(0.3808411053417259)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.015537794743329754), pvalue=np.float64(0.4358155327148556)),\n",
       " 'NDCG': np.float64(0.9453266196352341)}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.19513018009287456), pvalue=np.float64(5.691210910947871e-19)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.1886165233051777), pvalue=np.float64(8.30208566034678e-18)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.12766984630342632), pvalue=np.float64(5.330319333491061e-18)),\n",
       " 'NDCG': np.float64(0.9587084902943803)}"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(-0.019880558710830148), pvalue=np.float64(0.5058918830761372)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.013324702186238433), pvalue=np.float64(0.6557055344399361)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.009123225575569605), pvalue=np.float64(0.6472657002675055)),\n",
       " 'NDCG': np.float64(0.9423789475885137)}"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.19115419531407127), pvalue=np.float64(2.955607317074353e-18)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.1791347889737998), pvalue=np.float64(3.465029783295783e-16)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.12125506471169475), pvalue=np.float64(2.1817308807428052e-16)),\n",
       " 'NDCG': np.float64(0.9603128649387445)}"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.01698812984714948), pvalue=np.float64(0.5697323693928426)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.007677448244604918), pvalue=np.float64(0.7972690925765615)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.003755218895383514), pvalue=np.float64(0.850611442331823)),\n",
       " 'NDCG': np.float64(0.9475486945584475)}"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.15962486945995827), pvalue=np.float64(4.0060189730176745e-13)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.1605791757989239), pvalue=np.float64(2.892619985408547e-13)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.10856467162336156), pvalue=np.float64(1.9493009630003727e-13)),\n",
       " 'NDCG': np.float64(0.9546248728024769)}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(-0.06005101505509046), pvalue=np.float64(0.04431934247484312)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.08048141682780152), pvalue=np.float64(0.006992558488855497)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.05385979561811603), pvalue=np.float64(0.006907503567783921)),\n",
       " 'NDCG': np.float64(0.9450113141225648)}"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.14228674434383598), pvalue=np.float64(1.0562509114297515e-10)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.13941466731080687), pvalue=np.float64(2.499696138504226e-10)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09470476983905698), pvalue=np.float64(1.4211704436751063e-10)),\n",
       " 'NDCG': np.float64(0.9549664197621537)}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(-0.0035617366308346547), pvalue=np.float64(0.9051388669124685)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.020723371997561794), pvalue=np.float64(0.4880232059175057)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.014185852320171777), pvalue=np.float64(0.47679070798574963)),\n",
       " 'NDCG': np.float64(0.9458028781148465)}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.13763302834225488), pvalue=np.float64(4.228154394265886e-10)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.13270997461272996), pvalue=np.float64(1.7448595304914651e-09)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.08977766857457668), pvalue=np.float64(1.2023313140377907e-09)),\n",
       " 'NDCG': np.float64(0.9545439100272489)}"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(-0.019052168772135815), pvalue=np.float64(0.5237841829718719)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.02885638950590088), pvalue=np.float64(0.33419178509451997)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.02047636088910096), pvalue=np.float64(0.30443629563043206)),\n",
       " 'NDCG': np.float64(0.9427576638179417)}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.14744265193027772), pvalue=np.float64(2.1529697336529358e-11)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.14107528327940352), pvalue=np.float64(1.5222999806069971e-10)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.0956093754574017), pvalue=np.float64(9.489487435038506e-11)),\n",
       " 'NDCG': np.float64(0.9553584923280912)}"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(-0.020380819362867605), pvalue=np.float64(0.49524446584021287)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.03369882324725188), pvalue=np.float64(0.25938455936436633)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.024424032764722256), pvalue=np.float64(0.22059144274321507)),\n",
       " 'NDCG': np.float64(0.9425415676179754)}"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.14558193797617258), pvalue=np.float64(3.847273422064755e-11)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.1364729558339483), pvalue=np.float64(5.932157259632411e-10)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.09255579161149852), pvalue=np.float64(3.6554374524863544e-10)),\n",
       " 'NDCG': np.float64(0.9555285765079923)}"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(-0.031056310511023533), pvalue=np.float64(0.29863656032435565)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(-0.044949480156967196), pvalue=np.float64(0.132395526337161)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(-0.030803610481530082), pvalue=np.float64(0.12236640836597484)),\n",
       " 'NDCG': np.float64(0.9435047340434057)}"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = feature_importance[sorted_idx][-20:]\n",
    "feat_pool = list(x.columns[sorted_idx])[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, shift=0):\n",
    "    return 1 / (1 + np.exp(-(x-shift)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = sigmoid((1-feat_importances), shift=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = {feat: imp for feat, imp in zip(feat_pool, feat_importances)}\n",
    "feat_pool = {feat: desc[feat] for feat in feat_pool}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from prompt import CROSS_OVER_PROMPT, MUTATION_PROMPT, DEDUPLICATION_PROMPT, CODE_GEN_PROMPT\n",
    "\n",
    "def prompt_selection(task_id, desc, feat_pool, feat_importances):\n",
    "    if task_id == 0:\n",
    "        prompts = [CROSS_OVER_PROMPT.format(existing_features=desc, feat_pool=feat_pool)]\n",
    "    else:\n",
    "        pd = np.random.uniform(0, 1, len(feat_importances))\n",
    "        prompts = []\n",
    "        for i, (feat, imp) in enumerate(feat_importances.items()):\n",
    "            if pd[i] < imp:\n",
    "                feat = {feat: desc[feat]}\n",
    "                mutated_prompt = MUTATION_PROMPT.format(existing_features=desc, feature=feat)\n",
    "                prompts.append(mutated_prompt)\n",
    "    return prompts\n",
    "\n",
    "def mllm_single_inference(prompt, type=\"json\"):\n",
    "    payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_images[0]}\"\n",
    "            }\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_images[1]}\"\n",
    "            }\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_images[2]}\"\n",
    "            }\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_images[3]}\"\n",
    "            }\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt,\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 2000,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    response = response.json()['choices'][0]['message']['content'] \n",
    "    pattern = r\"```json([\\s\\S]*?)```\" if type == \"json\" else r\"```python([\\s\\S]*?)```\"\n",
    "    response = re.search(pattern, response).group(1).strip()\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "def feat_extractor(task_id, responses):\n",
    "    if task_id == 0:\n",
    "        new_feat = json.loads(responses[0])\n",
    "    else:\n",
    "        new_feat = {}\n",
    "        for response in responses:\n",
    "            new_feat.update(json.loads(response))\n",
    "            \n",
    "    return new_feat\n",
    "\n",
    "def featgen_inference(prompts):\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        response = mllm_single_inference(prompt)\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "def deduplicator(feat_pool, new_feat):\n",
    "    prompt = DEDUPLICATION_PROMPT.format(feat_pool=feat_pool, new_feat_pool=new_feat)\n",
    "    response = mllm_single_inference(prompt)\n",
    "    response = json.loads(response)\n",
    "    dup_feat = [r[\"feature\"] for r in response]\n",
    "    no_dup_feat = {k: v for k, v in new_feat.items() if k not in dup_feat}\n",
    "    return no_dup_feat\n",
    "\n",
    "def code_gen(new_feats):\n",
    "    responses = []\n",
    "    for new_feat, definition in new_feats.items():\n",
    "        prompt = CODE_GEN_PROMPT.format(feature={new_feat: definition}, feature_name=new_feat)\n",
    "        response = mllm_single_inference(prompt, type=\"python\")\n",
    "        responses.append(response)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids ={0: \"cross-over\", 1: \"mutation\"}\n",
    "task_prob =[1, 0.0] \n",
    "\n",
    "def genetic_instruct(feat_pool, feat_importances):\n",
    "    task_id = np.random.choice(list(task_ids.keys()), p=task_prob)\n",
    "    print(f\"Task: {task_ids[task_id]}\")\n",
    "    prompts = prompt_selection(task_id, desc, feat_pool, feat_importances)\n",
    "    responses = featgen_inference(prompts)\n",
    "    new_feats = feat_extractor(task_id, responses)\n",
    "    no_dup_feat = deduplicator(desc, new_feats)\n",
    "    return no_dup_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: cross-over\n",
      "{\n",
      "  \"macro_density_ratio\": \"the ratio of macro areas to the total layout area, indicating potential congestion regions\",\n",
      "  \"pin_cluster_density_peak\": \"maximum density of pin clusters within the layout, identifying critical congestion hotspots\",\n",
      "  \"rudy_pin_spatial_variability\": \"measure of spatial variability in RUDY pin values, indicating potential routing difficulty\",\n",
      "  \"macro_linear_alignment\": \"degree of linear alignment of macros, reflecting potential for straightforward routing paths\",\n",
      "  \"rudy_peak_clustering\": \"measure of clustering of RUDY peaks, indicating concentrated demand areas\",\n",
      "  \"macro_pin_alignment_score\": \"score reflecting alignment between macros and pin clusters, affecting routing efficiency\",\n",
      "  \"macro_edge_gradient_proximity\": \"average distance from macro edges to significant RUDY gradient changes, indicating potential routing challenges\",\n",
      "  \"pin_density_gradient\": \"gradient of pin density across the layout, indicating areas of rapid congestion change\",\n",
      "  \"macro_orientation_consistency\": \"consistency in macro orientations, indicating uniformity in potential routing paths\",\n",
      "  \"macro_to_pin_cluster_proximity\": \"average proximity distance from macros to pin clusters, affecting potential routing efficiency\"\n",
      "}\n",
      "[\n",
      "  {\n",
      "    \"feature\": \"macro_density_ratio\",\n",
      "    \"reason\": \"Similar to 'macro_area_ratio'; both measure the ratio of macro areas to the total layout area.\"\n",
      "  },\n",
      "  {\n",
      "    \"feature\": \"pin_cluster_density_peak\",\n",
      "    \"reason\": \"Similar to 'sector_pin_density_peak'; both identify peak densities in pin clusters indicating congestion.\"\n",
      "  },\n",
      "  {\n",
      "    \"feature\": \"rudy_pin_spatial_variability\",\n",
      "    \"reason\": \"Similar to 'rudy_variance_ratio'; both measure variability in RUDY pin values to indicate routing difficulty.\"\n",
      "  },\n",
      "  {\n",
      "    \"feature\": \"macro_edge_gradient_proximity\",\n",
      "    \"reason\": \"Similar to 'macro_edge_to_rudy_density_difference'; both measure proximity of macro edges to significant RUDY changes.\"\n",
      "  },\n",
      "  {\n",
      "    \"feature\": \"macro_orientation_consistency\",\n",
      "    \"reason\": \"Similar to 'macro_orientation_diversity'; both assess the consistency or diversity in macro orientations.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "new_feat_pool = genetic_instruct(feat_pool, feat_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_linear_alignment': 'degree of linear alignment of macros, reflecting potential for straightforward routing paths',\n",
       " 'rudy_peak_clustering': 'measure of clustering of RUDY peaks, indicating concentrated demand areas',\n",
       " 'macro_pin_alignment_score': 'score reflecting alignment between macros and pin clusters, affecting routing efficiency',\n",
       " 'pin_density_gradient': 'gradient of pin density across the layout, indicating areas of rapid congestion change',\n",
       " 'macro_to_pin_cluster_proximity': 'average proximity distance from macros to pin clusters, affecting potential routing efficiency'}"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "def macro_linear_alignment(images):\n",
      "    tiles_size = 2.25\n",
      "    macro_image = images[0]\n",
      "    rudy_image = images[1]\n",
      "    rudy_pin_image = images[2]\n",
      "    \n",
      "    image_height, image_width = macro_image.shape\n",
      "    total_image_area = image_width * image_height\n",
      "    \n",
      "    macro_image = np.uint8(macro_image * 255)\n",
      "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
      "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
      "    num_macros = len(contours)\n",
      "    \n",
      "    # Initialize alignment score\n",
      "    alignment_score = 0\n",
      "    \n",
      "    for contour in contours:\n",
      "        # Fit a bounding rectangle around each macro\n",
      "        x, y, w, h = cv2.boundingRect(contour)\n",
      "        \n",
      "        # Calculate aspect ratio of the rectangle\n",
      "        aspect_ratio = w / float(h)\n",
      "        \n",
      "        # Check if the rectangle is linear (either vertical or horizontal)\n",
      "        if aspect_ratio > 1.5 or aspect_ratio < 0.67:\n",
      "            alignment_score += 1\n",
      "\n",
      "    # Normalize the score by the number of macros\n",
      "    if num_macros > 0:\n",
      "        alignment_score /= num_macros\n",
      "    \n",
      "    # Calculate the feature value in micrometers\n",
      "    feature_value = alignment_score * tiles_size\n",
      "    \n",
      "    return {\"macro_linear_alignment\": feature_value}\n",
      "\n",
      "# Example usage:\n",
      "# macro_image, rudy_image, rudy_pin_image are numpy arrays with shape (256, 256) and values in [0, 1]\n",
      "# features = macro_linear_alignment([macro_image, rudy_image, rudy_pin_image])\n",
      "# print(features)\n"
     ]
    }
   ],
   "source": [
    "error_code = {\n",
    " 'macro_linear_alignment': 'degree of linear alignment of macros, reflecting potential for straightforward routing paths',\n",
    "}\n",
    "code_feat = code_gen(error_code)\n",
    "# code_feat = code_gen(new_feat_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 1 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_perimeter_ratio(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_perimeter = 2 * (image_width + image_height) * tiles_size\n",
    "\n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold the image to binary\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate total perimeter of macros\n",
    "    macro_perimeter = sum(cv2.arcLength(contour, True) for contour in contours) * tiles_size\n",
    "\n",
    "    # Calculate the macro perimeter ratio\n",
    "    macro_perimeter_ratio = macro_perimeter / total_image_perimeter\n",
    "\n",
    "    return {\"macro_perimeter_ratio\": macro_perimeter_ratio}\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def macro_orientation_diversity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]  # scaled to [0-255]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    orientations = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        angle = rect[-1]\n",
    "        \n",
    "        # Normalize the angle to [0, 90) range\n",
    "        if angle < -45:\n",
    "            angle += 90\n",
    "        orientations.append(angle)\n",
    "    \n",
    "    # Calculate diversity index\n",
    "    hist, _ = np.histogram(orientations, bins=10, range=(0, 90))\n",
    "    hist = hist / np.sum(hist)  # Normalize the histogram\n",
    "    diversity_index = entropy(hist)\n",
    "    \n",
    "    return {\"macro_orientation_diversity\": diversity_index}\n",
    "\n",
    "\n",
    "def macro_spacing_std(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro_image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Extract the bounding boxes of the macros\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    \n",
    "    # Calculate the center of each macro\n",
    "    macro_centers = [(x + w / 2, y + h / 2) for (x, y, w, h) in bounding_boxes]\n",
    "    \n",
    "    # Function to calculate Euclidean distance\n",
    "    def euclidean_distance(pt1, pt2):\n",
    "        return np.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "    \n",
    "    # Calculate all pairwise distances between macro centers\n",
    "    distances = []\n",
    "    for i in range(len(macro_centers)):\n",
    "        for j in range(i + 1, len(macro_centers)):\n",
    "            dist = euclidean_distance(macro_centers[i], macro_centers[j])\n",
    "            distances.append(dist * tiles_size)  # Convert to micrometers\n",
    "    \n",
    "    # Compute the standard deviation of the distances\n",
    "    if len(distances) > 1:\n",
    "        spacing_std = np.std(distances)\n",
    "    else:\n",
    "        spacing_std = 0.0  # No meaningful spacing if less than two macros\n",
    "    \n",
    "    return {\"macro_spacing_std\": spacing_std}\n",
    "\n",
    "\n",
    "def overlapping_macro_density(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "\n",
    "    # Convert macro image to 0-255 scale\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the macro image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Threshold for identifying high RUDY values\n",
    "    high_rudy_threshold = 0.5\n",
    "    high_rudy_mask = (rudy_image >= high_rudy_threshold).astype(np.uint8)\n",
    "\n",
    "    # Calculate overlapping area\n",
    "    overlap_area = 0\n",
    "    for contour in contours:\n",
    "        # Create a mask for this macro\n",
    "        macro_mask = np.zeros_like(macro_image)\n",
    "        cv2.drawContours(macro_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "        \n",
    "        # Calculate overlap between macro and high RUDY areas\n",
    "        overlap = cv2.bitwise_and(macro_mask, macro_mask, mask=high_rudy_mask)\n",
    "        overlap_area += cv2.countNonZero(overlap)\n",
    "    \n",
    "    # Calculate density\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_area_um2 = image_height * image_width * (tiles_size ** 2)\n",
    "    overlap_area_um2 = overlap_area * (tiles_size ** 2)\n",
    "    overlapping_density = overlap_area_um2 / total_area_um2\n",
    "\n",
    "    return {\"overlapping_macro_density\": overlapping_density}\n",
    "\n",
    "\n",
    "def macro_centroid_clustering(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroids = []\n",
    "    for cnt in contours:\n",
    "        M = cv2.moments(cnt)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            centroids.append((cx, cy))\n",
    "    \n",
    "    if len(centroids) < 2:\n",
    "        return {\"macro_centroid_clustering\": 0}\n",
    "    \n",
    "    # Calculate the average distance between each centroid and the mean centroid\n",
    "    centroids = np.array(centroids)\n",
    "    mean_centroid = np.mean(centroids, axis=0)\n",
    "    \n",
    "    # Compute the average distance to the mean centroid\n",
    "    distances = np.linalg.norm(centroids - mean_centroid, axis=1)\n",
    "    average_distance = np.mean(distances)\n",
    "    \n",
    "    # Convert to micrometers\n",
    "    average_distance_um = average_distance * tiles_size\n",
    "    \n",
    "    return {\"macro_centroid_clustering\": average_distance_um}\n",
    "\n",
    "\n",
    "def pin_distribution_evenness(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to uint8 format and binary image\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours to determine the number of macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Compute pin distribution evenness\n",
    "    image_height, image_width = rudy_pin_image.shape\n",
    "    total_pixels = image_height * image_width\n",
    "    \n",
    "    # Calculate the number of white pixels in the RUDY pin image\n",
    "    num_pin_pixels = np.sum(rudy_pin_image > 0.5)\n",
    "    \n",
    "    # Calculate pin distribution evenness\n",
    "    evenness = num_pin_pixels / total_pixels\n",
    "    \n",
    "    return {\"pin_distribution_evenness\": evenness}\n",
    "\n",
    "\n",
    "def macro_boundary_distance_var(images):\n",
    "    tiles_size = 2.25  # size in micrometers\n",
    "    macro_image = images[0]\n",
    "\n",
    "    # Convert the macro image to uint8\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "\n",
    "    # Threshold the image to get binary\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calculate distances from macro contours to image boundaries\n",
    "    distances = []\n",
    "    for contour in contours:\n",
    "        # Calculate bounding rect for each macro\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Calculate distances to each boundary (top, bottom, left, right)\n",
    "        top_dist = y\n",
    "        bottom_dist = macro_image.shape[0] - (y + h)\n",
    "        left_dist = x\n",
    "        right_dist = macro_image.shape[1] - (x + w)\n",
    "        \n",
    "        # Convert pixel distances to micrometers\n",
    "        top_dist_um = top_dist * tiles_size\n",
    "        bottom_dist_um = bottom_dist * tiles_size\n",
    "        left_dist_um = left_dist * tiles_size\n",
    "        right_dist_um = right_dist * tiles_size\n",
    "        \n",
    "        # Collect all boundary distances for the current macro\n",
    "        distances.extend([top_dist_um, bottom_dist_um, left_dist_um, right_dist_um])\n",
    "\n",
    "    # Calculate the variance of the distances\n",
    "    feature_value = np.var(distances)\n",
    "\n",
    "    return {\"macro_boundary_distance_var\": feature_value}\n",
    "\n",
    "\n",
    "def rudy_pin_correlation(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to uint8\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Compute rudy_pin_correlation\n",
    "    rudy_flat = rudy_image.flatten()\n",
    "    rudy_pin_flat = rudy_pin_image.flatten()\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(rudy_flat, rudy_pin_flat)[0, 1]\n",
    "    \n",
    "    return {\"rudy_pin_correlation\": correlation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_perimeter_ratio, macro_orientation_diversity, macro_spacing_std, overlapping_macro_density, macro_centroid_clustering, pin_distribution_evenness, macro_boundary_distance_var, rudy_pin_correlation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rudy_pin_correlation': np.float64(0.5816007018018947)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[7](image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_func_list = new_feat_func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc.update(new_feat_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 2 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_alignment_uniformity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255] range\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate centroid of each macro\n",
    "    centroids = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            centroids.append((cx, cy))\n",
    "    \n",
    "    # Calculate standard deviation of centroids' positions\n",
    "    centroids = np.array(centroids)\n",
    "    if len(centroids) > 0:\n",
    "        mean_x, mean_y = np.mean(centroids, axis=0)\n",
    "        std_dev = np.std(centroids, axis=0)\n",
    "        uniformity_score = np.mean(std_dev) * tiles_size  # Convert to micrometers\n",
    "    else:\n",
    "        uniformity_score = 0\n",
    "\n",
    "    feature_value = uniformity_score\n",
    "    return {\"macro_alignment_uniformity\": feature_value}\n",
    "\n",
    "# Usage\n",
    "# images = [macro_image, rudy_image, rudy_pin_image]\n",
    "# result = macro_alignment_uniformity(images)\n",
    "# print(result)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_edge_density(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size ** 2)  # Area in square micrometers\n",
    "    \n",
    "    # Convert macro image to uint8 [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours to detect edges\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate total edge length\n",
    "    total_edge_length = 0\n",
    "    for contour in contours:\n",
    "        total_edge_length += cv2.arcLength(contour, True)\n",
    "    \n",
    "    # Convert pixel edge length to micrometers\n",
    "    total_edge_length_um = total_edge_length * tiles_size\n",
    "    \n",
    "    # Calculate edge density (length per unit area)\n",
    "    macro_edge_density_value = total_edge_length_um / total_image_area\n",
    "    \n",
    "    return {\"macro_edge_density\": macro_edge_density_value}\n",
    "\n",
    "# Example usage\n",
    "# images = [macro_image, rudy_image, rudy_pin_image] # Load your images here\n",
    "# result = macro_edge_density(images)\n",
    "# print(result)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def mean_pin_density(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to 0-255\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Thresholding the macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours to count the number of macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the number of pins in the RUDY pin image\n",
    "    total_pins = np.sum(rudy_pin_image > 0)\n",
    "    \n",
    "    # Calculate the total image area in terms of micron^2\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area_um2 = (image_width * tiles_size) * (image_height * tiles_size)\n",
    "    \n",
    "    # Calculate mean pin density (pins per micron^2)\n",
    "    mean_pin_density_value = total_pins / total_image_area_um2\n",
    "\n",
    "    return {\"mean_pin_density\": mean_pin_density_value}\n",
    "\n",
    "# Example usage\n",
    "# images = [macro_image, rudy_image, rudy_pin_image]  # Images should be loaded as numpy arrays\n",
    "# feature_result = mean_pin_density(images)\n",
    "# print(feature_result)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def pin_clustering_factor(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    # Convert macro image to [0-255] range\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Thresholding to extract macros\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Process the rudy_pin_image\n",
    "    # Convert to binary (assuming pins are prominent in the image)\n",
    "    _, pin_binary = cv2.threshold(rudy_pin_image, 0.5, 1, cv2.THRESH_BINARY)\n",
    "    pin_binary = np.uint8(pin_binary * 255)\n",
    "    \n",
    "    # Find pin contours to detect clusters\n",
    "    pin_contours, _ = cv2.findContours(pin_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calculate pin clustering factor\n",
    "    # Example: Using average area of pin clusters\n",
    "    cluster_areas = [cv2.contourArea(c) for c in pin_contours]\n",
    "    if cluster_areas:\n",
    "        avg_cluster_area = np.mean(cluster_areas)\n",
    "    else:\n",
    "        avg_cluster_area = 0\n",
    "\n",
    "    # Convert area from pixel^2 to um^2\n",
    "    avg_cluster_area_um = avg_cluster_area * (tiles_size ** 2)\n",
    "\n",
    "    # Define pin_clustering_factor based on average cluster area\n",
    "    # Here a simple proportional relation; adjust based on specific criteria\n",
    "    pin_clustering_factor = avg_cluster_area_um / total_image_area\n",
    "\n",
    "    return {\"pin_clustering_factor\": pin_clustering_factor}\n",
    "\n",
    "def macro_to_pin_proximity_mean(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold the macro image to binary\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours for macro regions\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the centroids of macros\n",
    "    macro_centroids = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            macro_centroids.append((cx, cy))\n",
    "    \n",
    "    # Convert pin image to binary\n",
    "    pin_image = np.uint8(rudy_pin_image * 255)\n",
    "    _, binary_pin_image = cv2.threshold(pin_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours for pin regions\n",
    "    pin_contours, _ = cv2.findContours(binary_pin_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the centroids of pins\n",
    "    pin_centroids = []\n",
    "    for contour in pin_contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            pin_centroids.append((cx, cy))\n",
    "    \n",
    "    # Calculate the average proximity distance\n",
    "    total_distances = []\n",
    "    \n",
    "    for macro_cx, macro_cy in macro_centroids:\n",
    "        distances = []\n",
    "        for pin_cx, pin_cy in pin_centroids:\n",
    "            dist = np.sqrt((macro_cx - pin_cx) ** 2 + (macro_cy - pin_cy) ** 2)\n",
    "            distances.append(dist)\n",
    "        \n",
    "        if len(distances) > 0:\n",
    "            total_distances.append(min(distances) * tiles_size)\n",
    "    \n",
    "    # Compute mean distance if there are distances calculated\n",
    "    if total_distances:\n",
    "        feature_value = np.mean(total_distances)\n",
    "    else:\n",
    "        feature_value = 0\n",
    "    \n",
    "    return {\"macro_to_pin_proximity_mean\": feature_value}\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_diagonal_connectivity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255] scale\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Create an image to draw the contours\n",
    "    contour_image = np.zeros_like(binary_image)\n",
    "\n",
    "    # Draw contours on a blank image\n",
    "    cv2.drawContours(contour_image, contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Compute the distance transform\n",
    "    dist_transform = cv2.distanceTransform(contour_image, cv2.DIST_L2, 5)\n",
    "\n",
    "    # Calculate connectivity by analyzing diagonal distances\n",
    "    # Here we consider connectivity by looking for non-zero distances in the diagonal directions\n",
    "    diagonal_kernel = np.array([[1, 0, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 0, 1]], dtype=np.uint8)\n",
    "\n",
    "    diagonal_connectivity_map = cv2.filter2D((dist_transform > 0).astype(np.uint8), -1, diagonal_kernel)\n",
    "\n",
    "    # Calculate diagonal connectivity as the number of adjacent pixels in diagonals\n",
    "    diagonal_connectivity = np.sum(diagonal_connectivity_map > 0)\n",
    "\n",
    "    # Convert the result to physical units\n",
    "    feature_value_um = diagonal_connectivity * (tiles_size ** 2)\n",
    "\n",
    "    return {\"macro_diagonal_connectivity\": feature_value_um}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_alignment_uniformity, macro_edge_density, mean_pin_density, pin_clustering_factor, macro_to_pin_proximity_mean, macro_diagonal_connectivity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_to_pin_proximity_mean': np.float64(116.74554954438128)}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[4](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 3 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rudy_variance_ratio(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate variance of RUDY\n",
    "    rudy_variance = np.var(rudy_image)\n",
    "    \n",
    "    # Calculate variance of RUDY pin\n",
    "    rudy_pin_variance = np.var(rudy_pin_image)\n",
    "\n",
    "    # Calculate the variance ratio\n",
    "    if rudy_pin_variance != 0:\n",
    "        rudy_variance_ratio = rudy_variance / rudy_pin_variance\n",
    "    else:\n",
    "        rudy_variance_ratio = float('inf')  # Handle case where rudy_pin_variance is zero\n",
    "\n",
    "    return {\"rudy_variance_ratio\": rudy_variance_ratio}\n",
    "\n",
    "\n",
    "def rudy_gradation_smoothness(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Compute gradients of the RUDY image\n",
    "    rudy_dx = cv2.Sobel(rudy_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    rudy_dy = cv2.Sobel(rudy_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Compute the gradient magnitude\n",
    "    rudy_magnitude = np.sqrt(rudy_dx**2 + rudy_dy**2)\n",
    "    \n",
    "    # Calculate the smoothness as the average of gradient magnitudes\n",
    "    smoothness = np.mean(rudy_magnitude)\n",
    "    \n",
    "    return {\"rudy_gradation_smoothness\": smoothness}\n",
    "\n",
    "\n",
    "def layout_sector_congestion_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the average congestion in the RUDY image\n",
    "    rudy_congestion = np.mean(rudy_image)\n",
    "    \n",
    "    # Calculate the average congestion in the RUDY pin image\n",
    "    rudy_pin_congestion = np.mean(rudy_pin_image)\n",
    "    \n",
    "    # Congestion index calculation\n",
    "    congestion_index = (rudy_congestion + rudy_pin_congestion) / 2\n",
    "\n",
    "    # Calculate area of each pixel in um^2\n",
    "    pixel_area_um2 = tiles_size * tiles_size\n",
    "    \n",
    "    # Scale the congestion index by the number of macros and the pixel area\n",
    "    adjusted_congestion_index = congestion_index * num_macros * pixel_area_um2\n",
    "    \n",
    "    return {\"layout_sector_congestion_index\": adjusted_congestion_index}\n",
    "\n",
    "\n",
    "def macro_to_macro_proximity_min(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the minimum proximity distance between different macros\n",
    "    min_distance = float('inf')\n",
    "    \n",
    "    for i, cnt1 in enumerate(contours):\n",
    "        for j, cnt2 in enumerate(contours):\n",
    "            if i != j:\n",
    "                for point1 in cnt1:\n",
    "                    for point2 in cnt2:\n",
    "                        dist = cv2.norm(point1 - point2, cv2.NORM_L2)\n",
    "                        if dist < min_distance:\n",
    "                            min_distance = dist\n",
    "    \n",
    "    # Convert distance in pixels to micrometers\n",
    "    min_distance_um = min_distance * tiles_size\n",
    "    \n",
    "    return {\"macro_to_macro_proximity_min\": min_distance_um}\n",
    "\n",
    "\n",
    "def macro_edge_proximity_to_pins(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Binarize the macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Compute edge proximity\n",
    "    edge_distances = []\n",
    "\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            # Get the coordinates of the edge point\n",
    "            x, y = point[0]\n",
    "            \n",
    "            # Check the proximity to pin clusters\n",
    "            if np.any(rudy_pin_image[max(0, y-1):min(y+2, rudy_pin_image.shape[0]),\n",
    "                                     max(0, x-1):min(x+2, rudy_pin_image.shape[1])] > 0):\n",
    "                edge_distances.append((x, y))\n",
    "    \n",
    "    # Calculate the average proximity\n",
    "    average_proximity = len(edge_distances) * tiles_size\n",
    "    \n",
    "    return {\"macro_edge_proximity_to_pins\": average_proximity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [rudy_variance_ratio, rudy_gradation_smoothness, layout_sector_congestion_index, macro_to_macro_proximity_min, macro_edge_proximity_to_pins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnew_feat_func_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m(image_features)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "new_feat_func_list[0](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 4 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rudy_pin_gradient_intensity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 8-bit\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Compute the gradient of the RUDY pin image\n",
    "    grad_x = cv2.Sobel(rudy_pin_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(rudy_pin_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Calculate the gradient intensity\n",
    "    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    total_gradient_intensity = np.sum(gradient_magnitude)\n",
    "    \n",
    "    # Convert to units of um squared\n",
    "    area_per_pixel = tiles_size * tiles_size\n",
    "    total_gradient_intensity_um = total_gradient_intensity * area_per_pixel\n",
    "    \n",
    "    return {\"rudy_pin_gradient_intensity\": total_gradient_intensity_um}\n",
    "\n",
    "def macro_cluster_compactness(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size ** 2)  # Convert pixel area to um²\n",
    "    \n",
    "    # Convert macro image to 0-255 range\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate total macro area and perimeter\n",
    "    total_macro_area = 0\n",
    "    total_macro_perimeter = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour) * (tiles_size ** 2)  # Convert pixel area to um²\n",
    "        perimeter = cv2.arcLength(contour, True) * tiles_size  # Convert pixel perimeter to um\n",
    "        total_macro_area += area\n",
    "        total_macro_perimeter += perimeter\n",
    "    \n",
    "    # Calculate compactness: (Perimeter^2 / (4 * π * Area))\n",
    "    if total_macro_area > 0:\n",
    "        compactness = (total_macro_perimeter ** 2) / (4 * np.pi * total_macro_area)\n",
    "    else:\n",
    "        compactness = 0  # Avoid division by zero\n",
    "    \n",
    "    feature_value = compactness\n",
    "    return {\"macro_cluster_compactness\": feature_value}\n",
    "\n",
    "\n",
    "def pin_density_variance(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    # Convert macro image for contour detection\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Calculate pin densities\n",
    "    pin_densities = []\n",
    "\n",
    "    for contour in contours:\n",
    "        mask = np.zeros(rudy_pin_image.shape, dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, (1), thickness=cv2.FILLED)\n",
    "\n",
    "        # Calculate pin density in this region\n",
    "        pin_area = cv2.countNonZero(rudy_pin_image * mask)\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        pin_density = (pin_area / contour_area) if contour_area != 0 else 0\n",
    "        pin_densities.append(pin_density)\n",
    "\n",
    "    # Calculate variance of the pin densities\n",
    "    pin_density_variance = np.var(pin_densities)\n",
    "\n",
    "    return {\"pin_density_variance\": pin_density_variance}\n",
    "\n",
    "def sector_pin_density_peak(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Convert pixel size to micrometers\n",
    "    pixel_to_um = tiles_size\n",
    "    \n",
    "    # Find contours in macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the density (normalized) for the RUDY pin image\n",
    "    rudy_pin_density = np.sum(rudy_pin_image)\n",
    "\n",
    "    # Calculate pin density per sector\n",
    "    sector_height, sector_width = rudy_pin_image.shape\n",
    "    sector_pin_densities = []\n",
    "\n",
    "    for i in range(sector_height):\n",
    "        for j in range(sector_width):\n",
    "            # Calculate density per sector\n",
    "            pin_density = rudy_pin_image[i, j] / (pixel_to_um ** 2)\n",
    "            sector_pin_densities.append(pin_density)\n",
    "    \n",
    "    # Find peak density\n",
    "    peak_density = max(sector_pin_densities)\n",
    "    \n",
    "    # Convert density from per um^2 to peaks per sector area\n",
    "    sector_area_um2 = (pixel_to_um * sector_height) * (pixel_to_um * sector_width)\n",
    "    peak_density_per_sector_area = peak_density * sector_area_um2\n",
    "    \n",
    "    return {\"sector_pin_density_peak\": peak_density_per_sector_area}\n",
    "\n",
    "\n",
    "def macro_distance_to_rudy_peak(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find peaks in the RUDY map\n",
    "    rudy_peaks = np.where(rudy_image == rudy_image.max())\n",
    "    peak_points = np.array(list(zip(rudy_peaks[0], rudy_peaks[1])))\n",
    "    \n",
    "    # Calculate the macro centers\n",
    "    macro_centers = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            macro_centers.append((cX, cY))\n",
    "    \n",
    "    # Compute the distance from each macro center to the nearest RUDY peak\n",
    "    total_distance = 0\n",
    "    for center in macro_centers:\n",
    "        distances = np.sqrt((peak_points[:, 0] - center[0]) ** 2 + (peak_points[:, 1] - center[1]) ** 2)\n",
    "        min_distance = np.min(distances)\n",
    "        total_distance += min_distance\n",
    "    \n",
    "    # Calculate the average distance and convert to um\n",
    "    if len(macro_centers) > 0:\n",
    "        average_distance_pixels = total_distance / len(macro_centers)\n",
    "    else:\n",
    "        average_distance_pixels = 0\n",
    "\n",
    "    average_distance_um = average_distance_pixels * tiles_size\n",
    "    \n",
    "    return {\"macro_distance_to_rudy_peak\": average_distance_um}\n",
    "\n",
    "\n",
    "def aggregate_macro_rudy_visual_density(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size ** 2)\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    macro_area = sum(cv2.contourArea(c) for c in contours)\n",
    "    macro_area_um2 = macro_area * (tiles_size ** 2)\n",
    "    \n",
    "    rudy_density = np.mean(rudy_image)\n",
    "    \n",
    "    aggregate_macro_rudy_visual_density = (macro_area_um2 / total_image_area) * rudy_density\n",
    "    \n",
    "    return {\"aggregate_macro_rudy_visual_density\": aggregate_macro_rudy_visual_density}\n",
    "\n",
    "\n",
    "def pin_neighborhood_uniformity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate pin density\n",
    "    pin_density = np.sum(rudy_pin_image) / total_image_area\n",
    "    \n",
    "    # Calculate standard deviation of pin densities\n",
    "    pin_density_map = rudy_pin_image * (255 / np.amax(rudy_pin_image))\n",
    "    neighborhood_size = 5  # You can adjust this based on the desired neighborhood size\n",
    "    pin_density_stddev = np.std([cv2.mean(pin_density_map[y:y+neighborhood_size, x:x+neighborhood_size])[0]\n",
    "                                 for y in range(0, image_height, neighborhood_size)\n",
    "                                 for x in range(0, image_width, neighborhood_size)])\n",
    "    \n",
    "    # Normalize the standard deviation by the maximum possible standard deviation\n",
    "    max_possible_stddev = 255 / np.sqrt(total_image_area)\n",
    "    uniformity = 1 - (pin_density_stddev / max_possible_stddev)\n",
    "    \n",
    "    return {\"pin_neighborhood_uniformity\": uniformity}\n",
    "\n",
    "\n",
    "def multi_macro_interaction_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255] and get contours\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the area in um for one pixel\n",
    "    pixel_area = tiles_size * tiles_size\n",
    "    \n",
    "    # Initialize interaction index\n",
    "    interaction_index = 0\n",
    "    \n",
    "    # Iterate over each contour\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Create a mask for the current macro\n",
    "        macro_mask = np.zeros_like(macro_image)\n",
    "        cv2.drawContours(macro_mask, contours, i, 255, -1)\n",
    "        macro_mask = macro_mask / 255.0  # Convert mask to [0, 1]\n",
    "\n",
    "        # Calculate interaction with RUDY and RUDY Pin\n",
    "        rudy_interaction = np.sum(rudy_image * macro_mask) * pixel_area\n",
    "        rudy_pin_interaction = np.sum(rudy_pin_image * macro_mask) * pixel_area\n",
    "        \n",
    "        # Accumulate the interaction index\n",
    "        interaction_index += rudy_interaction + rudy_pin_interaction\n",
    "    \n",
    "    # Normalize by number of macros to get an average interaction index\n",
    "    if num_macros > 0:\n",
    "        interaction_index /= num_macros\n",
    "    \n",
    "    return {\"multi_macro_interaction_index\": interaction_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [rudy_pin_gradient_intensity, macro_cluster_compactness, pin_density_variance, sector_pin_density_peak, macro_distance_to_rudy_peak, aggregate_macro_rudy_visual_density, pin_neighborhood_uniformity, multi_macro_interaction_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multi_macro_interaction_index': np.float64(2998.0581551653468)}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[7](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 5 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rudy_pin_to_macro_centroid_distance(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro_image to [0-255] scale\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Binarize the macro image to identify macros\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calculate centroids of each macro\n",
    "    macro_centroids = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            macro_centroids.append((cx, cy))\n",
    "            \n",
    "    # Identify RUDY pin hotspots\n",
    "    rudy_pin_coords = np.argwhere(rudy_pin_image >= 0.5)\n",
    "    \n",
    "    # Calculate distance from each RUDY pin hotspot to each macro centroid\n",
    "    total_distance = 0\n",
    "    count = 0\n",
    "    \n",
    "    for pin_coord in rudy_pin_coords:\n",
    "        pin_x, pin_y = pin_coord\n",
    "        for mc in macro_centroids:\n",
    "            mc_x, mc_y = mc\n",
    "            distance = np.sqrt((pin_x - mc_x) ** 2 + (pin_y - mc_y) ** 2)\n",
    "            total_distance += distance\n",
    "            count += 1\n",
    "    \n",
    "    # Average distance calculation\n",
    "    if count > 0:\n",
    "        average_distance_pixels = total_distance / count\n",
    "    else:\n",
    "        average_distance_pixels = 0\n",
    "    \n",
    "    # Convert distance from pixels to micrometers\n",
    "    average_distance_um = average_distance_pixels * tiles_size\n",
    "    \n",
    "    return {\"rudy_pin_to_macro_centroid_distance\": average_distance_um}\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_overlap_coefficient(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size ** 2)\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours to identify macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate area for each macro\n",
    "    macro_areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "    \n",
    "    # Calculate total area covered by macros\n",
    "    total_macro_area = sum(macro_areas)\n",
    "    \n",
    "    # Calculate overlaps\n",
    "    overlap_area = total_macro_area - len(macro_areas) * (tiles_size ** 2)\n",
    "    overlap_area_um = overlap_area * (tiles_size ** 2)\n",
    "    \n",
    "    # Calculate overlap coefficient\n",
    "    macro_overlap_coefficient = overlap_area_um / total_image_area\n",
    "    \n",
    "    return {\"macro_overlap_coefficient\": macro_overlap_coefficient}\n",
    "\n",
    "# Example usage:\n",
    "# features = macro_overlap_coefficient([macro_img, rudy_img, rudy_pin_img])\n",
    "# print(features)\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import skew\n",
    "\n",
    "def pin_distribution_skewness(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 8-bit [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate pin distribution skewness\n",
    "    indices = np.argwhere(rudy_pin_image > 0)\n",
    "    x_coords, y_coords = indices[:, 1], indices[:, 0]\n",
    "\n",
    "    # Calculate the skewness of the pin distribution\n",
    "    skew_x = skew(x_coords)\n",
    "    skew_y = skew(y_coords)\n",
    "\n",
    "    # Average the skewness in both directions\n",
    "    pin_distribution_skewness = (skew_x + skew_y) / 2.0\n",
    "    \n",
    "    return {\"pin_distribution_skewness\": pin_distribution_skewness}\n",
    "\n",
    "\n",
    "def multi_sector_congestion_correlation(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image_uint8 = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Binarize the macro image\n",
    "    _, binary_image = cv2.threshold(macro_image_uint8, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours (macros) in the macro image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate features from RUDY images\n",
    "    rudy_flat = rudy_image.flatten()\n",
    "    rudy_pin_flat = rudy_pin_image.flatten()\n",
    "    \n",
    "    # Correlation between RUDY and RUDY pin\n",
    "    correlation = np.corrcoef(rudy_flat, rudy_pin_flat)[0, 1]\n",
    "    \n",
    "    # Normalize correlation value to ensure it's between -1 and 1 (if needed)\n",
    "    correlation = max(-1, min(1, correlation))\n",
    "    \n",
    "    # Define the feature\n",
    "    feature_value = correlation\n",
    "    \n",
    "    return {\"multi_sector_congestion_correlation\": feature_value}\n",
    "\n",
    "\n",
    "def macro_rudy_pin_alignment_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Binarize macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in macro image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate RUDY pin hotspots by finding non-zero areas in rudy_pin_image\n",
    "    rudy_pin_hotspots = cv2.findNonZero(np.uint8(rudy_pin_image))\n",
    "    \n",
    "    # Calculate alignment index\n",
    "    overlap_area = 0\n",
    "    if rudy_pin_hotspots is not None:\n",
    "        for cnt in contours:\n",
    "            mask = np.zeros(rudy_pin_image.shape, np.uint8)\n",
    "            cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "            masked_rudy_pin = cv2.bitwise_and(rudy_pin_image, rudy_pin_image, mask=mask)\n",
    "            overlap_area += np.count_nonzero(masked_rudy_pin)\n",
    "\n",
    "    # Convert overlap area to um²\n",
    "    overlap_area_um2 = overlap_area * (tiles_size ** 2)\n",
    "\n",
    "    # Alignment Index Calculation: Overlap Area / Total Macro Area\n",
    "    total_macro_area = cv2.countNonZero(binary_image) * (tiles_size ** 2)\n",
    "    alignment_index = overlap_area_um2 / total_macro_area if total_macro_area > 0 else 0\n",
    "    \n",
    "    return {\"macro_rudy_pin_alignment_index\": alignment_index}\n",
    "\n",
    "\n",
    "def macro_edge_to_rudy_density_difference(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro_image to uint8 for contour detection\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Initialize the difference sum\n",
    "    difference_sum = 0\n",
    "\n",
    "    # Process each macro to calculate the proximity to RUDY density\n",
    "    for contour in contours:\n",
    "        # Create a mask for the macro\n",
    "        mask = np.zeros_like(macro_image)\n",
    "        cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "        \n",
    "        # Dilate mask to get the edge area\n",
    "        dilated_mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=1)\n",
    "        edge_area = dilated_mask - mask\n",
    "        \n",
    "        # Calculate the average RUDY density on the edges\n",
    "        rudy_density_near_edge = cv2.mean(rudy_image, mask=edge_area)[0]\n",
    "        \n",
    "        # Calculate the average macro density (should be high near the edges)\n",
    "        macro_density_near_edge = cv2.mean(macro_image / 255.0, mask=edge_area)[0]\n",
    "        \n",
    "        # Calculate the density difference\n",
    "        density_difference = np.abs(macro_density_near_edge - rudy_density_near_edge)\n",
    "        \n",
    "        # Accumulate the difference\n",
    "        difference_sum += density_difference\n",
    "    \n",
    "    # Convert difference to area in um^2\n",
    "    # Assuming each pixel area is tiles_size x tiles_size\n",
    "    feature_value = difference_sum * (tiles_size ** 2)\n",
    "\n",
    "    return {\"macro_edge_to_rudy_density_difference\": feature_value}\n",
    "\n",
    "def rudy_peak_distribution_evenness(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Binarize macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Analyze RUDY peaks\n",
    "    rudy_peaks = np.where(rudy_image > np.mean(rudy_image), rudy_image, 0)\n",
    "    peak_sum = np.sum(rudy_peaks)\n",
    "    \n",
    "    # Calculate mean peak per tile\n",
    "    mean_peak = peak_sum / total_image_area\n",
    "    \n",
    "    # Calculate evenness as standard deviation of peak distribution\n",
    "    rudy_peak_distribution = (rudy_peaks / mean_peak)\n",
    "    evenness = np.std(rudy_peak_distribution)\n",
    "    \n",
    "    # Feature value should reflect distribution evenness\n",
    "    feature_value = evenness\n",
    "    \n",
    "    return {\"rudy_peak_distribution_evenness\": feature_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [rudy_pin_to_macro_centroid_distance, macro_overlap_coefficient, pin_distribution_skewness, multi_sector_congestion_correlation, macro_rudy_pin_alignment_index, macro_edge_to_rudy_density_difference, rudy_peak_distribution_evenness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rudy_pin_to_macro_centroid_distance': np.float64(261.224204310548)}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[0](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 6 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_to_rudy_gradient_alignment(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Detect edges in the RUDY image\n",
    "    rudy_edges = cv2.Canny(np.uint8(rudy_image * 255), 50, 150)\n",
    "    \n",
    "    # Initialize alignment score\n",
    "    alignment_score = 0\n",
    "\n",
    "    # Calculate alignment by checking proximity of edges to macro contours\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            if rudy_edges[y, x] > 0:  # if there's an edge in the rudy image at this macro location\n",
    "                alignment_score += 1\n",
    "\n",
    "    # Normalize the alignment score by the number of macros and image area\n",
    "    alignment_score /= (len(contours) * total_image_area)\n",
    "\n",
    "    # Calculate feature in µm\n",
    "    feature_value = alignment_score * (tiles_size ** 2)\n",
    "\n",
    "    return {\"macro_to_rudy_gradient_alignment\": feature_value}\n",
    "\n",
    "\n",
    "def macro_pin_path_complexity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro_image to [0-255] and binarize it\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours to count the number of macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Analyze RUDY and RUDY_pin images to estimate routing complexity\n",
    "    # Convert to [0-255] for processing\n",
    "    rudy_image_255 = np.uint8(rudy_image * 255)\n",
    "    rudy_pin_image_255 = np.uint8(rudy_pin_image * 255)\n",
    "    \n",
    "    # Find non-zero areas indicating routing intensity\n",
    "    rudy_nonzero = cv2.countNonZero(rudy_image_255)\n",
    "    rudy_pin_nonzero = cv2.countNonZero(rudy_pin_image_255)\n",
    "    \n",
    "    # Normalize by total pixels to get proportion\n",
    "    rudy_density = rudy_nonzero / total_image_area\n",
    "    rudy_pin_density = rudy_pin_nonzero / total_image_area\n",
    "    \n",
    "    # Complexity is modeled as interaction between RUDY densities and macro counts\n",
    "    complexity = (rudy_density + rudy_pin_density) * num_macros\n",
    "    \n",
    "    # Convert complexity to actual area in um\n",
    "    feature_value = complexity * tiles_size * tiles_size\n",
    "    \n",
    "    return {\"macro_pin_path_complexity\": feature_value}\n",
    "\n",
    "def sector_edge_rudy_density(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to binary\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate average RUDY density along sector edges\n",
    "    rudy_density = 0\n",
    "    total_edge_length = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Approximate contour to polygon and compute perimeter\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        # Find bounding box of polygon\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        \n",
    "        # Extract edge mask and calculate sum of RUDY densities along edges\n",
    "        edge_mask = np.zeros_like(rudy_image)\n",
    "        cv2.drawContours(edge_mask, [approx], -1, 1, 1)  # Draw edges\n",
    "        \n",
    "        edge_rudy_sum = np.sum(rudy_image * edge_mask)\n",
    "        edge_length = cv2.arcLength(approx, True) * tiles_size\n",
    "        \n",
    "        rudy_density += edge_rudy_sum\n",
    "        total_edge_length += edge_length\n",
    "    \n",
    "    # Compute average edge RUDY density\n",
    "    if total_edge_length > 0:\n",
    "        average_rudy_density = rudy_density / total_edge_length\n",
    "    else:\n",
    "        average_rudy_density = 0\n",
    "\n",
    "    return {\"sector_edge_rudy_density\": average_rudy_density}\n",
    "\n",
    "\n",
    "def rudy_consistency_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Calculate mean and standard deviation of RUDY values\n",
    "    mean_rudy = np.mean(rudy_image)\n",
    "    std_dev_rudy = np.std(rudy_image)\n",
    "\n",
    "    # Calculate RUDY Consistency Index\n",
    "    if mean_rudy != 0:\n",
    "        consistency_index = std_dev_rudy / mean_rudy\n",
    "    else:\n",
    "        consistency_index = 0\n",
    "    \n",
    "    feature_value = consistency_index\n",
    "\n",
    "    return {\"rudy_consistency_index\": feature_value}\n",
    "\n",
    "def cross_sector_macro_flow(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    sector_count = 4  # Example: dividing the layout into 4x4 grid\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Assume a simple 4x4 grid layout\n",
    "    sector_height = image_height // sector_count\n",
    "    sector_width = image_width // sector_count\n",
    "    \n",
    "    # Initialize a matrix to keep track of macro coverage per sector\n",
    "    sector_coverage = np.zeros((sector_count, sector_count))\n",
    "    \n",
    "    # Iterate over each macro and mark the sectors it covers\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            sector_x = x // sector_width\n",
    "            sector_y = y // sector_height\n",
    "            sector_coverage[sector_y, sector_x] = 1\n",
    "    \n",
    "    # Calculate total number of covered sectors\n",
    "    covered_sectors = np.sum(sector_coverage)\n",
    "    \n",
    "    # Calculate cross-sector macro flow\n",
    "    cross_sector_macro_flow_value = covered_sectors * (tiles_size ** 2)\n",
    "    \n",
    "    return {\"cross_sector_macro_flow\": cross_sector_macro_flow_value}\n",
    "\n",
    "\n",
    "def pin_to_macro_rudy_gradient_proximity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Binarize macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Compute gradients of RUDY image\n",
    "    grad_x = cv2.Sobel(rudy_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(rudy_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = cv2.magnitude(grad_x, grad_y)\n",
    "    \n",
    "    # Threshold gradients to find significant changes\n",
    "    _, gradient_thresh = cv2.threshold(gradient_magnitude, 0.1, 1, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Overlay pin image\n",
    "    combined_image = cv2.multiply(gradient_thresh, rudy_pin_image)\n",
    "    \n",
    "    # Calculate proximity by measuring overlap with macro regions\n",
    "    proximity_score = 0\n",
    "    for cnt in contours:\n",
    "        mask = np.zeros_like(combined_image)\n",
    "        cv2.drawContours(mask, [cnt], 0, 1, thickness=cv2.FILLED)\n",
    "        overlap = cv2.multiply(combined_image, mask)\n",
    "        proximity_score += np.sum(overlap)\n",
    "    \n",
    "    # Convert proximity score to real-world units\n",
    "    proximity_score_um = proximity_score * (tiles_size ** 2)\n",
    "    \n",
    "    return {\"pin_to_macro_rudy_gradient_proximity\": proximity_score_um}\n",
    "\n",
    "\n",
    "def aggregate_pin_hotspot_density(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255] grayscale\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Overlay RUDY and RUDY pin images\n",
    "    combined_image = np.minimum(rudy_image, rudy_pin_image)\n",
    "    \n",
    "    # Calculate the density of pin hotspots\n",
    "    total_hotspot_intensity = np.sum(combined_image)\n",
    "    aggregate_pin_hotspot_density = (total_hotspot_intensity / total_image_area) / (tiles_size ** 2)\n",
    "    \n",
    "    return {\"aggregate_pin_hotspot_density\": aggregate_pin_hotspot_density}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_to_rudy_gradient_alignment, macro_pin_path_complexity, sector_edge_rudy_density, rudy_consistency_index, cross_sector_macro_flow, pin_to_macro_rudy_gradient_proximity, aggregate_pin_hotspot_density]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_to_rudy_gradient_alignment': 7.724761962890625e-05}"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[0](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 7 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_center_to_rudy_pin_peak_distance(images):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    \n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Get image dimensions\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert the macro image to the required format\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate macro centers\n",
    "    macro_centers = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            macro_centers.append((cX, cY))\n",
    "    \n",
    "    # Identify RUDY pin peak\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(rudy_pin_image)\n",
    "    peak_x, peak_y = max_loc\n",
    "    \n",
    "    # Calculate distances from macro centers to RUDY pin peak\n",
    "    distances = []\n",
    "    for center in macro_centers:\n",
    "        dist = np.sqrt((center[0] - peak_x) ** 2 + (center[1] - peak_y) ** 2)\n",
    "        distances.append(dist * tiles_size)  # Convert from pixels to um\n",
    "    \n",
    "    # Handle case with no macros\n",
    "    if len(distances) == 0:\n",
    "        average_distance = 0\n",
    "    else:\n",
    "        average_distance = np.mean(distances)\n",
    "    \n",
    "    return {\"macro_center_to_rudy_pin_peak_distance\": average_distance}\n",
    "\n",
    "\n",
    "def sector_rudy_disparity(images):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    \n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Compute the RUDY disparity feature\n",
    "    # Normalize RUDY image to [0, 1]\n",
    "    rudy_normalized = np.array(rudy_image)\n",
    "    \n",
    "    # Divide the image into sectors (e.g., a grid of 4x4 for simplicity)\n",
    "    sector_size = 64  # Assuming a 4x4 grid for the 256x256 image\n",
    "    disparities = []\n",
    "    \n",
    "    for i in range(0, image_height, sector_size):\n",
    "        for j in range(0, image_width, sector_size):\n",
    "            # Extract the sector\n",
    "            sector = rudy_normalized[i:i+sector_size, j:j+sector_size]\n",
    "            \n",
    "            # Calculate the average RUDY value for the sector\n",
    "            sector_average = np.mean(sector)\n",
    "            disparities.append(sector_average)\n",
    "    \n",
    "    # Calculate disparity as the variance or standard deviation of sector averages\n",
    "    sector_rudy_disparity_value = np.std(disparities)\n",
    "    \n",
    "    # Convert the disparity value into correct units given:\n",
    "    # Each pixel is 2.25 um x 2.25 um\n",
    "    sector_rudy_disparity_um = sector_rudy_disparity_value * tiles_size\n",
    "    \n",
    "    return {\"sector_rudy_disparity\": sector_rudy_disparity_um}\n",
    "\n",
    "\n",
    "def rudy_pin_variance_stability(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the variance of the RUDY pin image\n",
    "    rudy_pin_vals = rudy_pin_image.flatten()\n",
    "    mean_rudy_pin = np.mean(rudy_pin_vals)\n",
    "    variance_rudy_pin = np.var(rudy_pin_vals)\n",
    "    \n",
    "    # Calculate the stability factor as the inverse of variance (more stable when variance is low)\n",
    "    stability_factor = 1 / (variance_rudy_pin + 1e-6)  # Add a small value to avoid division by zero\n",
    "    \n",
    "    feature_value = stability_factor\n",
    "    \n",
    "    return {\"rudy_pin_variance_stability\": feature_value}\n",
    "\n",
    "\n",
    "def macro_corner_count(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Convert contours to polygons and find corners\n",
    "    num_corners = 0\n",
    "    for contour in contours:\n",
    "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        num_corners += len(approx)\n",
    "    \n",
    "    feature_value = num_corners\n",
    "    \n",
    "    return {\"macro_corner_count\": feature_value}\n",
    "\n",
    "\n",
    "def pin_distance_to_rudy_edge(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro_image to uint8 [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Threshold the RUDY image to find high density regions\n",
    "    _, high_rudy_thresh = cv2.threshold(rudy_image, 0.5, 1, cv2.THRESH_BINARY)\n",
    "    high_rudy_thresh = high_rudy_thresh.astype(np.uint8)\n",
    "    \n",
    "    # Find contours of high RUDY density\n",
    "    high_rudy_contours, _ = cv2.findContours(high_rudy_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Compute distance transform of high RUDY density regions\n",
    "    distance_transform = cv2.distanceTransform(1 - high_rudy_thresh, cv2.DIST_L2, 5)\n",
    "    \n",
    "    # Find contours of pin clusters in the RUDY pin image\n",
    "    _, pin_thresh = cv2.threshold(rudy_pin_image, 0.5, 1, cv2.THRESH_BINARY)\n",
    "    pin_thresh = pin_thresh.astype(np.uint8)\n",
    "    pin_contours, _ = cv2.findContours(pin_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate average distance of pin clusters to high RUDY density edges\n",
    "    total_distance = 0\n",
    "    total_pin_points = 0\n",
    "    \n",
    "    for contour in pin_contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            distance = distance_transform[y, x] * tiles_size\n",
    "            total_distance += distance\n",
    "            total_pin_points += 1\n",
    "    \n",
    "    average_distance = total_distance / total_pin_points if total_pin_points > 0 else 0\n",
    "    \n",
    "    return {\"pin_distance_to_rudy_edge\": average_distance}\n",
    "\n",
    "def macro_edge_intersection_density(images):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area_um = (image_width * tiles_size) * (image_height * tiles_size)\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours for macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create an empty image to draw edges\n",
    "    edges_img = np.zeros_like(binary_image)\n",
    "\n",
    "    # Draw contours as lines on edges_img\n",
    "    cv2.drawContours(edges_img, contours, -1, (255), 1)\n",
    "\n",
    "    # Use Canny edge detector to detect edges\n",
    "    edges = cv2.Canny(edges_img, 50, 150)\n",
    "\n",
    "    # Use Hough Transform to find lines (representing macro edges)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=20, minLineLength=5, maxLineGap=10)\n",
    "\n",
    "    intersection_points = set()\n",
    "\n",
    "    if lines is not None:\n",
    "        # Convert from pixels to um\n",
    "        lines = [(x1 * tiles_size, y1 * tiles_size, x2 * tiles_size, y2 * tiles_size) for line in lines for x1, y1, x2, y2 in line]\n",
    "        \n",
    "        # Check intersection between every line pair\n",
    "        for i in range(len(lines)):\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                line1 = lines[i]\n",
    "                line2 = lines[j]\n",
    "                intersection = find_intersection(line1, line2)\n",
    "                if intersection:\n",
    "                    intersection_points.add(intersection)\n",
    "    \n",
    "    # Calculate intersection density\n",
    "    num_intersections = len(intersection_points)\n",
    "    intersection_density = num_intersections / total_image_area_um\n",
    "    \n",
    "    return {\"macro_edge_intersection_density\": intersection_density}\n",
    "\n",
    "def find_intersection(line1, line2):\n",
    "    # Unpack points\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "\n",
    "    # Calculate determinants\n",
    "    det1 = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
    "    if det1 == 0:\n",
    "        return None  # Lines are parallel\n",
    "\n",
    "    t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / det1\n",
    "    u = ((x1 - x3) * (y1 - y2) - (y1 - y3) * (x1 - x2)) / det1\n",
    "    \n",
    "    # Check if intersection is within line segments\n",
    "    if 0 <= t <= 1 and 0 <= u <= 1:\n",
    "        # Calculate intersection point\n",
    "        px = x1 + t * (x2 - x1)\n",
    "        py = y1 + t * (y2 - y1)\n",
    "        return (round(px, 5), round(py, 5))\n",
    "\n",
    "    return None\n",
    "\n",
    "def pin_to_macro_edge_proximity_std(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]  # Not used in this function\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    \n",
    "    # Convert macro image to binary\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of the macro regions\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a mask for the macro contours\n",
    "    macro_mask = np.zeros_like(macro_image)\n",
    "    cv2.drawContours(macro_mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    # Calculate distance from each point to the nearest macro edge\n",
    "    dist_to_macro_edge = cv2.distanceTransform(255 - macro_mask, cv2.DIST_L2, 3)\n",
    "    \n",
    "    # Consider only pin regions from the RUDY pin image\n",
    "    pin_indices = np.where(rudy_pin_image > 0.5)\n",
    "    \n",
    "    # Gather distances of pins to nearest macro edges\n",
    "    pin_distances = dist_to_macro_edge[pin_indices]\n",
    "    \n",
    "    # Convert distances from pixels to um\n",
    "    pin_distances_um = pin_distances * tiles_size\n",
    "    \n",
    "    # Calculate the standard deviation\n",
    "    proximity_std = np.std(pin_distances_um)\n",
    "    \n",
    "    return {\"pin_to_macro_edge_proximity_std\": proximity_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_center_to_rudy_pin_peak_distance, sector_rudy_disparity, rudy_pin_variance_stability, macro_corner_count, pin_distance_to_rudy_edge, macro_edge_intersection_density, pin_to_macro_edge_proximity_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pin_distance_to_rudy_edge': np.float32(50.40145)}"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[4](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 8 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def macro_linear_alignment(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Initialize alignment score\n",
    "    alignment_score = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Fit a bounding rectangle around each macro\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Calculate aspect ratio of the rectangle\n",
    "        aspect_ratio = w / float(h)\n",
    "        \n",
    "        # Check if the rectangle is linear (either vertical or horizontal)\n",
    "        if aspect_ratio > 1.5 or aspect_ratio < 0.67:\n",
    "            alignment_score += 1\n",
    "\n",
    "    # Normalize the score by the number of macros\n",
    "    if num_macros > 0:\n",
    "        alignment_score /= num_macros\n",
    "    \n",
    "    # Calculate the feature value in micrometers\n",
    "    feature_value = alignment_score * tiles_size\n",
    "    \n",
    "    return {\"macro_linear_alignment\": feature_value}\n",
    "\n",
    "\n",
    "def rudy_peak_clustering(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image for contour detection\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Identify RUDY peaks\n",
    "    rudy_threshold_value = 0.8  # Example value, tune as necessary\n",
    "    _, rudy_peaks = cv2.threshold(rudy_image, rudy_threshold_value, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Detect connected components (clusters) in RUDY peaks\n",
    "    num_labels, labels_im = cv2.connectedComponents(np.uint8(rudy_peaks))\n",
    "\n",
    "    # Calculate clustering metric\n",
    "    peak_clusters = [np.sum(labels_im == i) for i in range(1, num_labels)]\n",
    "    clustering_score = np.sum(np.array(peak_clusters) ** 2) / total_image_area\n",
    "\n",
    "    return {\"rudy_peak_clustering\": clustering_score * (tiles_size ** 2)}\n",
    "\n",
    "\n",
    "def macro_pin_alignment_score(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 8-bit\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate macro boundaries\n",
    "    macro_boundaries = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    \n",
    "    # Calculate pin clusters\n",
    "    _, rudy_pin_thresh = cv2.threshold(rudy_pin_image, 0.5, 1, cv2.THRESH_BINARY)\n",
    "    rudy_pin_thresh = np.uint8(rudy_pin_thresh * 255)\n",
    "    pin_contours, _ = cv2.findContours(rudy_pin_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    pin_boundaries = [cv2.boundingRect(cnt) for cnt in pin_contours]\n",
    "    \n",
    "    # Calculate alignment score\n",
    "    alignment_score = 0\n",
    "    for macro in macro_boundaries:\n",
    "        macro_x, macro_y, macro_w, macro_h = macro\n",
    "        for pin in pin_boundaries:\n",
    "            pin_x, pin_y, pin_w, pin_h = pin\n",
    "            \n",
    "            # Check if the pin cluster is aligned with the macro boundary\n",
    "            if (macro_x <= pin_x <= macro_x + macro_w) and (macro_y <= pin_y <= macro_y + macro_h):\n",
    "                pin_area = pin_w * pin_h\n",
    "                alignment_score += pin_area\n",
    "\n",
    "    # Convert score to um^2\n",
    "    alignment_score *= (tiles_size ** 2)\n",
    "\n",
    "    return {\"macro_pin_alignment_score\": alignment_score}\n",
    "\n",
    "\n",
    "def pin_density_gradient(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold to create a binary image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the gradient of the RUDY pin image\n",
    "    sobelx = cv2.Sobel(rudy_pin_image, cv2.CV_64F, 1, 0, ksize=5)  # Gradient in x-direction\n",
    "    sobely = cv2.Sobel(rudy_pin_image, cv2.CV_64F, 0, 1, ksize=5)  # Gradient in y-direction\n",
    "    gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    # Normalize the gradient magnitude to represent density change\n",
    "    max_gradient = np.max(gradient_magnitude)\n",
    "    if max_gradient > 0:\n",
    "        normalized_gradient = gradient_magnitude / max_gradient\n",
    "    else:\n",
    "        normalized_gradient = gradient_magnitude\n",
    "    \n",
    "    # Calculate the pin density gradient\n",
    "    pin_density_gradient_value = np.sum(normalized_gradient) * (tiles_size**2)\n",
    "    \n",
    "    return {\"pin_density_gradient\": pin_density_gradient_value}\n",
    "\n",
    "\n",
    "def macro_to_pin_cluster_proximity(images):\n",
    "    tiles_size = 2.25  # size of each pixel in micrometers\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the macro image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Find pin clusters (bright areas) in the RUDY pin image\n",
    "    _, pin_clusters = cv2.threshold(np.uint8(rudy_pin_image * 255), 127, 255, cv2.THRESH_BINARY)\n",
    "    pin_centroids = cv2.connectedComponentsWithStats(pin_clusters, connectivity=8)[3][1:]  # skip the background\n",
    "    \n",
    "    # Calculate average proximity distance from each macro to pin clusters\n",
    "    total_distance = 0\n",
    "    num_distances = 0\n",
    "    \n",
    "    for macro_contour in contours:\n",
    "        macro_centroid = np.mean(macro_contour, axis=0)[0]  # Get the centroid of the macro\n",
    "        for pin_centroid in pin_centroids:\n",
    "            distance_pixels = np.linalg.norm(macro_centroid - pin_centroid)\n",
    "            distance_um = distance_pixels * tiles_size\n",
    "            total_distance += distance_um\n",
    "            num_distances += 1\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if num_distances > 0:\n",
    "        average_proximity_distance = total_distance / num_distances\n",
    "    else:\n",
    "        average_proximity_distance = 0\n",
    "    \n",
    "    return {\"macro_to_pin_cluster_proximity\": average_proximity_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_linear_alignment, rudy_peak_clustering, macro_pin_alignment_score, pin_density_gradient, macro_to_pin_cluster_proximity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_linear_alignment': 0.6}"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[0](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 9 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def congestion_flow_coefficient(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Calculate image dimensions in micrometers\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area_um = (image_width * tiles_size) * (image_height * tiles_size)\n",
    "    \n",
    "    # Threshold macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Compute RUDY image gradients\n",
    "    grad_x = cv2.Sobel(rudy_image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    grad_y = cv2.Sobel(rudy_image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    \n",
    "    # Calculate gradient magnitudes and directions\n",
    "    magnitude, angle = cv2.cartToPolar(grad_x, grad_y, angleInDegrees=True)\n",
    "    \n",
    "    # Select pixels with significant magnitude\n",
    "    threshold_magnitude = 0.1  # This can be adjusted based on typical values\n",
    "    significant_magnitudes = magnitude > threshold_magnitude\n",
    "    \n",
    "    # Calculate histograms of angles for significant gradients\n",
    "    angle_hist, _ = np.histogram(angle[significant_magnitudes], bins=36, range=(0, 360))\n",
    "    \n",
    "    # Calculate congestion flow coefficient (normalized entropy of the angle distribution)\n",
    "    angle_distribution = angle_hist / np.sum(angle_hist)\n",
    "    entropy = -np.sum(angle_distribution * np.log2(angle_distribution + np.finfo(float).eps))\n",
    "    \n",
    "    congestion_flow_coefficient_value = entropy / np.log2(len(angle_hist))\n",
    "    \n",
    "    return {\"congestion_flow_coefficient\": congestion_flow_coefficient_value}\n",
    "\n",
    "# Test with your images\n",
    "# feature_result = congestion_flow_coefficient([macro_image, rudy_image, rudy_pin_image])\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def routing_stability_metric(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate difference between RUDY and RUDY pin images\n",
    "    rudy_diff = np.abs(rudy_image - rudy_pin_image)\n",
    "    \n",
    "    # Find average RUDY difference within macro regions\n",
    "    rudy_diff_macro = cv2.bitwise_and(rudy_diff, rudy_diff, mask=binary_image)\n",
    "    avg_rudy_diff_macro = np.sum(rudy_diff_macro) / (num_macros * tiles_size ** 2)  # Normalize by macro area\n",
    "    \n",
    "    # Calculate average RUDY outside macro regions\n",
    "    inverse_binary_image = cv2.bitwise_not(binary_image)\n",
    "    rudy_diff_non_macro = cv2.bitwise_and(rudy_diff, rudy_diff, mask=inverse_binary_image)\n",
    "    non_macro_area = total_image_area - np.sum(binary_image > 0)\n",
    "    avg_rudy_diff_non_macro = np.sum(rudy_diff_non_macro) / (non_macro_area * tiles_size ** 2)\n",
    "\n",
    "    # Routing stability metric as ratio of within-macro to outside-macro changes\n",
    "    routing_stability_metric = avg_rudy_diff_macro / (avg_rudy_diff_non_macro + 1e-6)  # Avoid division by zero\n",
    "\n",
    "    return {\"routing_stability_metric\": routing_stability_metric}\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def macro_distribution_entropy(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    \n",
    "    # Convert macro image to [0, 255] range\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold to create binary image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours to identify macro regions\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the area of each macro\n",
    "    macro_areas = [cv2.contourArea(contour) for contour in contours]\n",
    "    \n",
    "    # Calculate total macro area (in um²)\n",
    "    macro_areas_um = np.array(macro_areas) * (tiles_size ** 2)\n",
    "    \n",
    "    # Compute probability distribution of macro areas\n",
    "    area_distribution = macro_areas_um / macro_areas_um.sum()\n",
    "    \n",
    "    # Compute entropy of the area distribution\n",
    "    macro_entropy = entropy(area_distribution)\n",
    "    \n",
    "    return {\"macro_distribution_entropy\": macro_entropy}\n",
    "\n",
    "# Example usage\n",
    "# images = [macro_image, rudy_image, rudy_pin_image]\n",
    "# result = macro_distribution_entropy(images)\n",
    "# print(result)\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def rudy_pin_wavefront_detection(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Convert RUDY pin image to the [0-255] range for better edge detection\n",
    "    rudy_pin_image_uint8 = np.uint8(rudy_pin_image * 255)\n",
    "    \n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(rudy_pin_image_uint8, 50, 150)\n",
    "    \n",
    "    # Find contours to identify wavefront-like formations\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the total length of contours in micrometers\n",
    "    total_edge_length_um = sum(cv2.arcLength(cnt, True) for cnt in contours) * tiles_size\n",
    "    \n",
    "    feature_value = total_edge_length_um\n",
    "\n",
    "    return {\"rudy_pin_wavefront_detection\": feature_value}\n",
    "\n",
    "# Example of using the function\n",
    "# images = [macro_image_array, rudy_image_array, rudy_pin_image_array]\n",
    "# feature = rudy_pin_wavefront_detection(images)\n",
    "# print(feature)\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def routing_ease_score(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert the macro image to 0-255\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold the macro image to binary\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate macro area\n",
    "    macro_area = sum(cv2.contourArea(c) for c in contours)\n",
    "    macro_area_um2 = macro_area * (tiles_size ** 2)\n",
    "    \n",
    "    # Calculate average RUDY values to estimate routing demand\n",
    "    avg_rudy_intensity = np.mean(rudy_image)\n",
    "    avg_rudy_pin_intensity = np.mean(rudy_pin_image)\n",
    "    \n",
    "    # Combine metrics into a routing ease score\n",
    "    # This is a hypothetical formula for demonstration purposes\n",
    "    routing_score = (1 / (num_macros + 1)) * (1 / (avg_rudy_intensity + avg_rudy_pin_intensity + 1))\n",
    "    routing_ease_score = routing_score * 100  # Scale if necessary\n",
    "    \n",
    "    return {\"routing_ease_score\": routing_ease_score}\n",
    "\n",
    "\n",
    "def macro_edge_congestion_coefficient(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 0-255\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a mask for edges\n",
    "    edge_mask = np.zeros_like(macro_image)\n",
    "    cv2.drawContours(edge_mask, contours, -1, (255), thickness=1)\n",
    "    \n",
    "    # Convert edge_mask to 0-1 scale\n",
    "    edge_mask = edge_mask.astype(float) / 255\n",
    "    \n",
    "    # Calculate congestion around macro edges in RUDY image\n",
    "    congestion_around_edges = np.sum(edge_mask * rudy_image)\n",
    "    \n",
    "    # Calculate the area of macro edges\n",
    "    macro_edges_area = np.sum(edge_mask)\n",
    "    \n",
    "    # Calculate the coefficient\n",
    "    # Note: This example calculates an average congestion per unit edge area.\n",
    "    if macro_edges_area > 0:\n",
    "        macro_edge_congestion_coefficient = (congestion_around_edges / macro_edges_area) * (tiles_size**2)\n",
    "    else:\n",
    "        macro_edge_congestion_coefficient = 0\n",
    "    \n",
    "    return {\"macro_edge_congestion_coefficient\": macro_edge_congestion_coefficient}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [congestion_flow_coefficient, routing_stability_metric, macro_distribution_entropy, rudy_pin_wavefront_detection, routing_ease_score, macro_edge_congestion_coefficient]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 10 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_heatmap_intensity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255] range\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of macro blocks\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # High-density RUDY threshold\n",
    "    threshold_rudy = 0.5  # example threshold for high density\n",
    "    \n",
    "    # Calculate macro intensity in high-density RUDY areas\n",
    "    high_density_rudy_areas = (rudy_image >= threshold_rudy).astype(np.uint8)\n",
    "    \n",
    "    macro_rudy_overlap = cv2.bitwise_and(high_density_rudy_areas, high_density_rudy_areas, mask=binary_image)\n",
    "    \n",
    "    # Measure overlap area\n",
    "    overlap_area = np.sum(macro_rudy_overlap)\n",
    "    \n",
    "    # Convert overlap area from pixels to um^2\n",
    "    overlap_area_um2 = overlap_area * (tiles_size ** 2)\n",
    "    \n",
    "    # Intensity is overlap area relative to total macro area\n",
    "    total_macro_area = np.sum(binary_image / 255)  # sum of pixels in macro areas\n",
    "    total_macro_area_um2 = total_macro_area * (tiles_size ** 2)\n",
    "    \n",
    "    if total_macro_area_um2 > 0:\n",
    "        feature_value = overlap_area_um2 / total_macro_area_um2\n",
    "    else:\n",
    "        feature_value = 0\n",
    "\n",
    "    return {\"macro_heatmap_intensity\": feature_value}\n",
    "\n",
    "def instantaneous_congestion_peaks(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    # Convert macro image to [0-255] range for processing\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold and find contours in the macro image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate instantaneous congestion peaks using RUDY image\n",
    "    # Find peaks in RUDY by checking the mean intensity\n",
    "    rudy_mean_intensity = np.mean(rudy_image)\n",
    "    peak_threshold = rudy_mean_intensity + (np.max(rudy_image) - rudy_mean_intensity) * 0.5\n",
    "    congestion_peaks_rudy = np.where(rudy_image > peak_threshold, 1, 0)\n",
    "    \n",
    "    # Calculate the area of the peaks\n",
    "    peak_area = np.sum(congestion_peaks_rudy) * (tiles_size ** 2)\n",
    "    \n",
    "    # Return the feature dictionary with the calculated peak area\n",
    "    return {\"instantaneous_congestion_peaks\": peak_area}\n",
    "\n",
    "\n",
    "def macro_grid_alignment_coefficient(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to uint8 and threshold\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate grid alignment coefficient\n",
    "    num_macros = len(contours)\n",
    "    alignment_count = 0\n",
    "    \n",
    "    for contour in contours: \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Check alignment with grid lines\n",
    "        if x % tiles_size == 0 and y % tiles_size == 0:\n",
    "            alignment_count += 1\n",
    "    \n",
    "    # Calculate coefficient\n",
    "    if num_macros > 0:\n",
    "        grid_alignment_coefficient = alignment_count / num_macros\n",
    "    else:\n",
    "        grid_alignment_coefficient = 0\n",
    "    \n",
    "    return {\"macro_grid_alignment_coefficient\": grid_alignment_coefficient}\n",
    "\n",
    "\n",
    "def localized_routing_resilience(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size**2)  # in square micrometers\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold to extract macro regions\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate congestion impact using RUDY and RUDY pin images\n",
    "    rudy_congestion = np.sum(rudy_image) / (image_height * image_width)\n",
    "    rudy_pin_congestion = np.sum(rudy_pin_image) / (image_height * image_width)\n",
    "\n",
    "    # Define localized routing resilience\n",
    "    # You can adjust the formula as needed to represent resilience accurately\n",
    "    resilience_factor = 1.0  # Base resilience factor\n",
    "    congestion_difference = np.abs(rudy_congestion - rudy_pin_congestion)\n",
    "    \n",
    "    # Calculate the resilience by considering macro coverage impact\n",
    "    # This simple formula can be adjusted as needed\n",
    "    resilience = resilience_factor / (1 + congestion_difference * num_macros)\n",
    "    \n",
    "    # Convert resilience to desired units, if necessary\n",
    "    resilience_um = resilience * tiles_size  # This is just an example scaling\n",
    "    \n",
    "    return {\"localized_routing_resilience\": resilience_um}\n",
    "\n",
    "def macro_core_density_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold the macro image to create a binary image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of macros\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the total macro area in pixels\n",
    "    macro_area_pixels = sum(cv2.contourArea(contour) for contour in contours)\n",
    "    \n",
    "    # Convert macro area to square micrometers\n",
    "    macro_area_um2 = macro_area_pixels * (tiles_size ** 2)\n",
    "    \n",
    "    # Calculate core area if applicable (assuming full image is the core)\n",
    "    core_area_um2 = total_image_area * (tiles_size ** 2)\n",
    "    \n",
    "    # Calculate macro core density index\n",
    "    macro_core_density_index = macro_area_um2 / core_area_um2\n",
    "    \n",
    "    return {\"macro_core_density_index\": macro_core_density_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_heatmap_intensity, instantaneous_congestion_peaks, macro_grid_alignment_coefficient, localized_routing_resilience, macro_core_density_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_core_density_index': 0.55206298828125}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[4](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 11 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adaptive_routing_compliance(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 8-bit\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate RUDY and RUDY pin areas and compliance\n",
    "    rudy_threshold = 0.5\n",
    "    rudy_pin_threshold = 0.5\n",
    "    \n",
    "    rudy_congestion_area = np.sum(rudy_image > rudy_threshold) * tiles_size**2\n",
    "    rudy_pin_congestion_area = np.sum(rudy_pin_image > rudy_pin_threshold) * tiles_size**2\n",
    "\n",
    "    adaptive_compliance = (rudy_congestion_area + rudy_pin_congestion_area) / total_image_area\n",
    "\n",
    "    return {\"adaptive_routing_compliance\": adaptive_compliance}\n",
    "\n",
    "def macro_entry_exit_ratio(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro_image to [0-255] range\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate entry and exit points using RUDY and Rudy Pin images\n",
    "    rudy_threshold = 0.5  # threshold for dense areas\n",
    "    rudy_dense_areas = rudy_image > rudy_threshold\n",
    "    rudy_pin_entry_points = cv2.countNonZero(np.uint8(rudy_pin_image * rudy_dense_areas))\n",
    "    \n",
    "    rudy_pin_exit_points = np.count_nonzero(rudy_pin_image * (1 - rudy_dense_areas))\n",
    "\n",
    "    # Calculate the entry-exit ratio\n",
    "    if rudy_pin_exit_points == 0:\n",
    "        macro_entry_exit_ratio = float('inf')  # Avoid division by zero\n",
    "    else:\n",
    "        macro_entry_exit_ratio = rudy_pin_entry_points / rudy_pin_exit_points\n",
    "    \n",
    "    macro_entry_exit_ratio_um = macro_entry_exit_ratio * tiles_size  # Convert to um\n",
    "    \n",
    "    return {\"macro_entry_exit_ratio\": macro_entry_exit_ratio_um}\n",
    "\n",
    "\n",
    "def pin_density_continuity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Smooth the RUDY pin image to analyze continuity of density\n",
    "    smoothed_pin_image = cv2.GaussianBlur(rudy_pin_image, (5, 5), 0)\n",
    "    \n",
    "    # Calculate the gradients to assess continuity\n",
    "    grad_x = cv2.Sobel(smoothed_pin_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(smoothed_pin_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Calculate gradient magnitude\n",
    "    grad_magnitude = cv2.magnitude(grad_x, grad_y)\n",
    "    \n",
    "    # Normalize the gradient magnitude to [0, 1]\n",
    "    grad_magnitude /= np.max(grad_magnitude)\n",
    "    \n",
    "    # Compute the average gradient, representing pin density continuity\n",
    "    average_continuity = np.mean(1 - grad_magnitude)\n",
    "    \n",
    "    # Calculate continuity in terms of area (um)\n",
    "    continuity_um = average_continuity * total_image_area * (tiles_size**2)\n",
    "    \n",
    "    feature_value = continuity_um\n",
    "    \n",
    "    return {\"pin_density_continuity\": feature_value}\n",
    "\n",
    "\n",
    "def macro_weighted_connectivity(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize connectivity weight\n",
    "    connectivity_weight = 0\n",
    "    \n",
    "    # Total area covered by one pixel in um^2\n",
    "    pixel_area_um2 = tiles_size * tiles_size\n",
    "\n",
    "    for contour in contours:\n",
    "        # Compute the bounding rectangle for each macro\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Calculate the connectivity weight for this macro\n",
    "        macro_rudy_region = rudy_image[y:y+h, x:x+w]\n",
    "        macro_rudy_pin_region = rudy_pin_image[y:y+h, x:x+w]\n",
    "        \n",
    "        weight_rudy = np.sum(macro_rudy_region)\n",
    "        weight_rudy_pin = np.sum(macro_rudy_pin_region)\n",
    "        \n",
    "        # Total connectivity weight for this macro\n",
    "        macro_connectivity = weight_rudy + weight_rudy_pin\n",
    "        \n",
    "        # Accumulate the weighted connectivity\n",
    "        macro_area_pixels = cv2.contourArea(contour)\n",
    "        macro_area_um2 = macro_area_pixels * pixel_area_um2\n",
    "        \n",
    "        connectivity_weight += macro_connectivity * macro_area_um2 / total_image_area\n",
    "\n",
    "    return {\"macro_weighted_connectivity\": connectivity_weight}\n",
    "\n",
    "def routing_interference_resilience(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_height * image_width\n",
    "\n",
    "    # Convert macro image to binary\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Calculate RUDY intensity\n",
    "    rudy_intensity = np.sum(rudy_image)\n",
    "\n",
    "    # Calculate RUDY pin intensity\n",
    "    rudy_pin_intensity = np.sum(rudy_pin_image)\n",
    "\n",
    "    # Calculate macro area\n",
    "    macro_area = np.sum(binary_image > 0) * (tiles_size ** 2)\n",
    "\n",
    "    # Compute routing interference resilience\n",
    "    # A simple metric could be the ratio of RUDY pin intensity to RUDY intensity\n",
    "    if rudy_intensity > 0:\n",
    "        ri_resilience = rudy_pin_intensity / rudy_intensity\n",
    "    else:\n",
    "        ri_resilience = 0\n",
    "\n",
    "    # Convert feature to micrometers squared or other meaningful area unit\n",
    "    feature_value = ri_resilience * (tiles_size ** 2)\n",
    "\n",
    "    return {\"routing_interference_resilience\": feature_value}\n",
    "\n",
    "\n",
    "def pin_accessibility_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size ** 2)\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the total RUDY pin value (sum of all intensities)\n",
    "    rudy_pin_value = np.sum(rudy_pin_image)\n",
    "    \n",
    "    # Calculate the total RUDY value\n",
    "    rudy_value = np.sum(rudy_image)\n",
    "    \n",
    "    # Calculate pin accessibility index\n",
    "    if rudy_value > 0:\n",
    "        pin_accessibility_index = (rudy_pin_value / rudy_value) * num_macros\n",
    "    else:\n",
    "        pin_accessibility_index = 0\n",
    "    \n",
    "    return {\"pin_accessibility_index\": pin_accessibility_index}\n",
    "\n",
    "\n",
    "def macro_nesting_factor(images):\n",
    "    tiles_size = 2.25\n",
    "    \n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 0-255\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Calculate area covered by macros\n",
    "    macro_area = 0\n",
    "    for contour in contours:\n",
    "        macro_area += cv2.contourArea(contour)\n",
    "    \n",
    "    macro_area_um = macro_area * (tiles_size ** 2)\n",
    "\n",
    "    # Calculate RUDY area (non-zero pixels in RUDY image)\n",
    "    rudy_area = np.count_nonzero(rudy_image)\n",
    "    rudy_area_um = rudy_area * (tiles_size ** 2)\n",
    "    \n",
    "    # Calculate RUDY Pin area (non-zero pixels in RUDY pin image)\n",
    "    rudy_pin_area = np.count_nonzero(rudy_pin_image)\n",
    "    rudy_pin_area_um = rudy_pin_area * (tiles_size ** 2)\n",
    "    \n",
    "    # Estimate nesting factor\n",
    "    # It is a ratio of macro area to a combined area of RUDY and RUDY pin,\n",
    "    # illustrating how macros integrate with routing elements.\n",
    "    if (rudy_area_um + rudy_pin_area_um) == 0:\n",
    "        nesting_factor = 0\n",
    "    else:\n",
    "        nesting_factor = (macro_area_um) / (rudy_area_um + rudy_pin_area_um)\n",
    "\n",
    "    return {\"macro_nesting_factor\": nesting_factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [adaptive_routing_compliance, macro_entry_exit_ratio, pin_density_continuity, macro_weighted_connectivity, routing_interference_resilience, pin_accessibility_index, macro_nesting_factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_nesting_factor': 0.2760357061112383}"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_func_list[6](image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 12 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def macro_density_heat_factor(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Calculate the macro area in pixels\n",
    "    macro_area = cv2.countNonZero(binary_image)\n",
    "    \n",
    "    # Sum up the RUDY values where the macros are placed\n",
    "    macro_heat_map = cv2.bitwise_and(rudy_image, rudy_image, mask=binary_image)\n",
    "    total_macro_heat = np.sum(macro_heat_map)\n",
    "    \n",
    "    # Compute macro density heat factor\n",
    "    macro_density_heat_factor = 0\n",
    "    if macro_area > 0:\n",
    "        macro_density_heat_factor = total_macro_heat / macro_area\n",
    "\n",
    "    # Convert area from pixels to micrometers squared for documentation\n",
    "    macro_area_um2 = macro_area * (tiles_size ** 2)\n",
    "\n",
    "    return {\n",
    "        \"macro_density_heat_factor\": macro_density_heat_factor,\n",
    "        \"macro_area_um2\": macro_area_um2,\n",
    "        \"num_macros\": len(contours)\n",
    "    }\n",
    "\n",
    "\n",
    "def pin_routing_interference_score(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate overlap area between RUDY and RUDY pin images\n",
    "    overlap_area = np.sum((rudy_image > 0) & (rudy_pin_image > 0))\n",
    "    \n",
    "    # Calculate routing demand area\n",
    "    routing_demand_area = np.sum(rudy_image > 0)\n",
    "    \n",
    "    # Calculate pin congestion area\n",
    "    pin_congestion_area = np.sum(rudy_pin_image > 0)\n",
    "    \n",
    "    # Normalize the overlap by the routing and pin demand areas\n",
    "    normalized_overlap = (overlap_area / (routing_demand_area + 1e-5)) * (overlap_area / (pin_congestion_area + 1e-5))\n",
    "    \n",
    "    # Use the normalized overlap to calculate the interference score\n",
    "    interference_score = normalized_overlap * num_macros / total_image_area\n",
    "    \n",
    "    # Convert to physical units (um^2)\n",
    "    interference_score_um = interference_score * (tiles_size ** 2)\n",
    "    \n",
    "    feature_name = \"pin_routing_interference_score\"\n",
    "    feature_value = interference_score_um\n",
    "    \n",
    "    return {feature_name: feature_value}\n",
    "\n",
    "def macro_interaction_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height  # in pixels\n",
    "\n",
    "    # Scale the macro image to [0, 255]\n",
    "    macro_image_uint8 = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold and find contours in the macro image\n",
    "    _, binary_image = cv2.threshold(macro_image_uint8, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate the area of macros in micrometers squared\n",
    "    macro_area_pixels = cv2.countNonZero(binary_image)\n",
    "    macro_area_um2 = macro_area_pixels * (tiles_size ** 2)\n",
    "    \n",
    "    # Calculate the average RUDY demand in the region covered by macros\n",
    "    avg_rudy_in_macro_area = np.mean(rudy_image[binary_image == 255])\n",
    "    \n",
    "    # Calculate the average RUDY pin density in the region covered by macros\n",
    "    avg_rudy_pin_in_macro_area = np.mean(rudy_pin_image[binary_image == 255])\n",
    "\n",
    "    # Calculate interaction index as a function of macro overlap with routing demand\n",
    "    interaction_index = (avg_rudy_in_macro_area + avg_rudy_pin_in_macro_area) * macro_area_um2 / total_image_area\n",
    "\n",
    "    # Normalize the interaction index by the number of macros\n",
    "    if num_macros > 0:\n",
    "        interaction_index /= num_macros\n",
    "\n",
    "    return {\"macro_interaction_index\": interaction_index}\n",
    "\n",
    "\n",
    "def rudy_distribution_roughness(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate mean and standard deviation of RUDY values\n",
    "    rudy_mean = np.mean(rudy_image)\n",
    "    rudy_std = np.std(rudy_image)\n",
    "    \n",
    "    # Calculate roughness as deviation from the mean\n",
    "    roughness = rudy_std / rudy_mean if rudy_mean != 0 else 0\n",
    "    \n",
    "    # Convert roughness into desired unit (um)\n",
    "    feature_value = roughness * tiles_size\n",
    "    \n",
    "    return {\"rudy_distribution_roughness\": feature_value}\n",
    "\n",
    "def macro_congestion_influence(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "\n",
    "    # Threshold the macro image to create a binary image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of the macro areas\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    macro_congestion_influence = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        # Calculate the area of each macro in pixel²\n",
    "        macro_area_pixels = cv2.contourArea(contour)\n",
    "\n",
    "        # Convert macro area to um²\n",
    "        macro_area_um2 = macro_area_pixels * (tiles_size ** 2)\n",
    "        \n",
    "        # Calculate bounding box for macro\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Calculate congestion influence within macro bounding box on RUDY image\n",
    "        local_rudy_region = rudy_image[y:y+h, x:x+w]\n",
    "        local_rudy_average_density = np.mean(local_rudy_region)\n",
    "\n",
    "        # Influence contribution of this macro\n",
    "        influence_contribution = macro_area_um2 * local_rudy_average_density\n",
    "        macro_congestion_influence += influence_contribution\n",
    "\n",
    "    return {\"macro_congestion_influence\": macro_congestion_influence}\n",
    "\n",
    "def pin_utilization_efficiency(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate pin area\n",
    "    pin_area = np.sum(rudy_pin_image)\n",
    "    \n",
    "    # Calculate RUDY area (demand)\n",
    "    rudy_area = np.sum(rudy_image)\n",
    "    \n",
    "    # Pin Utilization Efficiency\n",
    "    if rudy_area != 0:\n",
    "        efficiency = pin_area / rudy_area\n",
    "    else:\n",
    "        efficiency = 0\n",
    "    \n",
    "    # Convert feature to um\n",
    "    efficiency *= total_image_area * tiles_size**2\n",
    "    \n",
    "    return {\"pin_utilization_efficiency\": efficiency}\n",
    "\n",
    "\n",
    "def congestion_decay_factor(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to 0-255 scale\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold to create binary image\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours for macro regions\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate overall routing demands\n",
    "    total_rudy_demand = np.sum(rudy_image)\n",
    "    total_rudy_pin_demand = np.sum(rudy_pin_image)\n",
    "    \n",
    "    # Calculate average demands\n",
    "    avg_rudy_demand = total_rudy_demand / (image_width * image_height)\n",
    "    avg_rudy_pin_demand = total_rudy_pin_demand / (image_width * image_height)\n",
    "    \n",
    "    # Find the peak congested area\n",
    "    peak_congestion_area = np.max(rudy_image)\n",
    "    \n",
    "    # Calculate the decay factor by how sharp the drop-off from peak congestion is\n",
    "    congestion_decay_factor = peak_congestion_area / (avg_rudy_demand + avg_rudy_pin_demand + 1e-5)  # added small number to avoid division by zero\n",
    "    \n",
    "    # Convert the factor from pixel-based to micrometer-based\n",
    "    congestion_decay_factor_um = congestion_decay_factor * (tiles_size**2) \n",
    "\n",
    "    return {\"congestion_decay_factor\": congestion_decay_factor_um}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [macro_density_heat_factor, pin_routing_interference_score, macro_interaction_index, rudy_distribution_roughness, macro_congestion_influence, pin_utilization_efficiency, congestion_decay_factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stage 13 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def demarcated_macro_proximity_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    \n",
    "    # Threshold the macro image to find contours of the macros\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Threshold for defining high-density areas in RUDY map\n",
    "    rudy_threshold = 0.5\n",
    "    \n",
    "    # Identifying high-density zones in RUDY\n",
    "    high_density_zone = rudy_image > rudy_threshold\n",
    "    \n",
    "    # Initialize a variable to accumulate proximity measure\n",
    "    proximity_sum = 0\n",
    "    \n",
    "    # Calculate proximity index\n",
    "    for contour in contours:\n",
    "        macro_mask = np.zeros_like(macro_image)\n",
    "        cv2.drawContours(macro_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "        \n",
    "        intersection = np.logical_and(macro_mask > 0, high_density_zone)\n",
    "        intersection_area = np.sum(intersection) * tiles_size * tiles_size\n",
    "        \n",
    "        # Proximity for current macro\n",
    "        proximity_sum += intersection_area\n",
    "        \n",
    "    # Normalizing by total macro area\n",
    "    total_macro_area = np.sum(macro_image > 0) * tiles_size * tiles_size\n",
    "    demarcated_macro_proximity_index = (proximity_sum / (total_macro_area + 1e-5)) if total_macro_area > 0 else 0\n",
    "    \n",
    "    return {\"demarcated_macro_proximity_index\": demarcated_macro_proximity_index}\n",
    "\n",
    "\n",
    "def macro_surface_irregularity_index(images):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height * (tiles_size ** 2)  # Convert area to micrometers\n",
    "\n",
    "    macro_image = np.uint8(macro_image * 255)  # Convert macro image to [0-255]\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Calculate total perimeter and area of macros\n",
    "    total_perimeter = 0\n",
    "    total_macro_area = 0\n",
    "    for contour in contours:\n",
    "        total_perimeter += cv2.arcLength(contour, True)\n",
    "        total_macro_area += cv2.contourArea(contour)\n",
    "\n",
    "    # Convert perimeter and area to micrometers\n",
    "    total_perimeter_um = total_perimeter * tiles_size\n",
    "    total_macro_area_um = total_macro_area * (tiles_size ** 2)\n",
    "\n",
    "    # Irregularity index calculation\n",
    "    if total_macro_area_um > 0:\n",
    "        irregularity_index = total_perimeter_um / total_macro_area_um\n",
    "    else:\n",
    "        irregularity_index = 0\n",
    "\n",
    "    return {\"macro_surface_irregularity_index\": irregularity_index}\n",
    "\n",
    "\n",
    "def macro_rudy_boundary_interaction_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Calculate interaction index\n",
    "    interaction_index = 0\n",
    "    \n",
    "    # Iterate over each contour\n",
    "    for contour in contours:\n",
    "        # Create a mask of the macro contour\n",
    "        contour_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "        cv2.drawContours(contour_mask, [contour], -1, (1), thickness=cv2.FILLED)\n",
    "        \n",
    "        # Calculate the intersection of the macro contour with RUDY pin image\n",
    "        interaction_area = np.sum(contour_mask * rudy_pin_image)\n",
    "        \n",
    "        # Convert pixels to area in um^2 (each pixel is 2.25um x 2.25um)\n",
    "        interaction_area_um = interaction_area * (tiles_size ** 2)\n",
    "        \n",
    "        # Check if the averaged RUDY pin density along macro boundary indicates congestion\n",
    "        if interaction_area > 0:\n",
    "            interaction_index += interaction_area_um / cv2.arcLength(contour, True) * tiles_size\n",
    "\n",
    "    return {\"macro_rudy_boundary_interaction_index\": interaction_index}\n",
    "\n",
    "def pin_density_peak_contrast(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "\n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "\n",
    "    # Convert macro image to [0-255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "\n",
    "    # Compute pin density peaks\n",
    "    # Using a kernel to emphasize local density peaks\n",
    "    kernel_size = 3  # Define an appropriate kernel size\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size**2)\n",
    "    smoothed_rudy_pin = cv2.filter2D(rudy_pin_image, -1, kernel)\n",
    "    \n",
    "    # Find pin density peak contrast\n",
    "    pin_density_peak = np.max(smoothed_rudy_pin)\n",
    "    avg_density_around_peaks = np.mean(smoothed_rudy_pin)\n",
    "    \n",
    "    # Compute the contrast\n",
    "    contrast = pin_density_peak - avg_density_around_peaks\n",
    "\n",
    "    # Convert image dimensions to a physical measurement\n",
    "    contrast_um = contrast * tiles_size  # Convert to um using the tile size\n",
    "    \n",
    "    return {\"pin_density_peak_contrast\": contrast_um}\n",
    "\n",
    "\n",
    "def rudy_pin_density_flux_index(images):\n",
    "    tiles_size = 2.25\n",
    "    macro_image = images[0]\n",
    "    rudy_image = images[1]\n",
    "    rudy_pin_image = images[2]\n",
    "    \n",
    "    image_height, image_width = macro_image.shape\n",
    "    total_image_area = image_width * image_height\n",
    "    \n",
    "    # Convert macro image to [0, 255]\n",
    "    macro_image = np.uint8(macro_image * 255)\n",
    "    _, binary_image = cv2.threshold(macro_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_macros = len(contours)\n",
    "    \n",
    "    # Process the RUDY pin image\n",
    "    # Compute the gradients along the x and y axis\n",
    "    grad_x = cv2.Sobel(rudy_pin_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(rudy_pin_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Compute the gradient magnitude\n",
    "    grad_magnitude = cv2.magnitude(grad_x, grad_y)\n",
    "    \n",
    "    # Calculate the mean of the gradient magnitude to represent density flux\n",
    "    mean_flux = np.mean(grad_magnitude)\n",
    "    \n",
    "    # Normalize to area in square micrometers (um^2)\n",
    "    pixel_area = tiles_size ** 2\n",
    "    total_area_um2 = total_image_area * pixel_area\n",
    "    \n",
    "    feature_value = mean_flux / total_area_um2\n",
    "    \n",
    "    return {\"rudy_pin_density_flux_index\": feature_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_func_list = [demarcated_macro_proximity_index, macro_surface_irregularity_index, macro_rudy_boundary_interaction_index, pin_density_peak_contrast, rudy_pin_density_flux_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_func_list = [feat_func for feat_func in feat_func_list if feat_func.__name__ in list(feat_pool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_func_list = feat_func_list + new_feat_func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.macro_spacing_std(images)>,\n",
       " <function __main__.macro_boundary_distance_var(images)>,\n",
       " <function __main__.pin_clustering_factor(images)>,\n",
       " <function __main__.macro_diagonal_connectivity(images)>,\n",
       " <function __main__.rudy_gradation_smoothness(images)>,\n",
       " <function __main__.macro_edge_proximity_to_pins(images)>,\n",
       " <function __main__.macro_cluster_compactness(images)>,\n",
       " <function __main__.pin_density_variance(images)>,\n",
       " <function __main__.pin_neighborhood_uniformity(images)>,\n",
       " <function __main__.rudy_consistency_index(images)>,\n",
       " <function __main__.pin_to_macro_rudy_gradient_proximity(images)>,\n",
       " <function __main__.sector_rudy_disparity(images)>,\n",
       " <function __main__.macro_corner_count(images)>,\n",
       " <function __main__.pin_to_macro_edge_proximity_std(images)>,\n",
       " <function __main__.macro_linear_alignment(images)>,\n",
       " <function __main__.rudy_peak_clustering(images)>,\n",
       " <function __main__.macro_pin_alignment_score(images)>,\n",
       " <function __main__.pin_density_gradient(images)>,\n",
       " <function __main__.macro_to_pin_cluster_proximity(images)>]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc.update(new_feat_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.1620306253279757), pvalue=np.float64(1.756106861244282e-13)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.15238662831895927), pvalue=np.float64(4.441483368274774e-12)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.10324405491747932), pvalue=np.float64(2.7117940054428016e-12)),\n",
       " 'NDCG': np.float64(0.9563442146691672)}"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLCC': PearsonRResult(statistic=np.float64(0.053704252167761604), pvalue=np.float64(0.0721477508880103)),\n",
       " 'SRCC': SignificanceResult(statistic=np.float64(0.04733534395902077), pvalue=np.float64(0.1130394311076796)),\n",
       " 'KRCC': SignificanceResult(statistic=np.float64(0.030647739472742457), pvalue=np.float64(0.12426901769601753)),\n",
       " 'NDCG': np.float64(0.9454307047877671)}"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_design(test_df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pool = {\n",
    "    'rudy_gradient_variability': 'the variation in gradient changes across the rudy map indicating potential areas of abrupt routing demand shifts',\n",
    "    'clustered_macro_distance_std': 'the standard deviation of distances between clustered groups of macros',\n",
    "    'rudy_pin_clustering_coefficient': 'a measure of how many rudy pins cluster together relative to the total number of rudy pins',\n",
    "    'macro_density_gradient': 'the change in macro density across the layout, impacting local congestion',\n",
    "    'macro_aspect_ratio_variance': 'the variance in aspect ratios of macros, indicating potential alignment and spacing issues that may impact congestion',\n",
    "    'macro_compactness_index': 'a measure of how closely packed the macros are, potentially affecting routing paths and congestion',\n",
    "    'rudy_pin_compaction_ratio': 'the ratio of compacted rudy pin clusters to the total number of rudy pins, indicating areas with high potential routing conflicts',\n",
    "    'macro_variability_coefficient': 'a measure of the consistency in macro sizes and shapes relative to each other, potentially affecting congestion balance',\n",
    "    'macro_symmetry_coefficient': 'a measure of the symmetry in macro placements relative to the overall layout, potentially influencing uniformity in congestion distribution',\n",
    "    'macro_cluster_density_contrast': 'the contrast in density between clustered groups of macros and their surrounding layout areas, indicating potential localized congestion pressure',\n",
    "    'rudy_pin_distribution_kurtosis': 'a measure of the peakedness or flatness in the distribution of rudy pins across the layout, indicating potential areas of concentrated or dispersed routing demand',\n",
    "    'localized_rudy_variability_coefficient': 'a measure of the variation in RUDY intensity within localized regions, indicating potential micro-level congestion fluctuations',\n",
    "    'macro_distribution_clarity_index': 'a measure of how distinct macro distributions are across the layout, indicating clarity in separation and potential influence on congestion distribution',\n",
    "    'rudy_direction_consistency_index': 'a measure of the uniformity in the directional flow of RUDY intensity, indicating how consistent the routing demand is across the layout',\n",
    "    'rudy_pin_area_masking_index': 'the ratio of the area masked by rudy pin regions relative to the total layout, indicating potential routing blockages',\n",
    "    'rudy_pin_gradient_convergence': 'a measure of how gradients in the rudy pin map converge into specific regions, indicating high-density pin clusters',\n",
    "    'rudy_intensity_symmetry_index': 'a measure of the symmetry in the RUDY intensity map across the layout, indicating uniformity in routing demand distribution',\n",
    "    'rudy_deviation_effect_index': 'a measure of the deviation of RUDY intensities from the mean, indicating areas of abnormal routing demand',\n",
    "    'demarcated_macro_proximity_index': 'a measure of how close macros are to predefined boundary regions, potentially affecting routing and congestion near layout edges',\n",
    "    'macro_surface_irregularity_index': 'a measure of the irregularity in macro surface shapes, which can impact routing paths and layout clarity',\n",
    "    'macro_rudy_boundary_interaction_index': 'a measure of the interaction between macros and high RUDY regions, indicating potential congestion hotspots',\n",
    "    'pin_density_peak_contrast': 'the contrast between peak pin density regions and their surroundings, indicating areas of abrupt routing demand changes',\n",
    "    'rudy_pin_density_flux_index': 'a measure of the rate of change in rudy pin density across the layout, indicating dynamic routing demand shifts',\n",
    "    'high_density_rudy_ratio': 'the ratio of areas with high RUDY intensity to the total layout area, indicating overall routing demand hotspots',\n",
    "    'high_density_rudy_pin_ratio': 'the ratio of areas with high RUDY pin intensity to the total layout area, indicating localized pin density hotspots'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_func_list = [\n",
    " rudy_gradient_variability,\n",
    " clustered_macro_distance_std,\n",
    " rudy_pin_clustering_coefficient,\n",
    " macro_density_gradient,\n",
    " macro_aspect_ratio_variance,\n",
    " macro_compactness_index,\n",
    " rudy_pin_compaction_ratio,\n",
    " macro_variability_coefficient,\n",
    " macro_symmetry_coefficient,\n",
    " macro_cluster_density_contrast,\n",
    " rudy_pin_distribution_kurtosis,\n",
    " localized_rudy_variability_coefficient,\n",
    " macro_distribution_clarity_index,\n",
    " rudy_direction_consistency_index,\n",
    " rudy_pin_area_masking_index,\n",
    " rudy_pin_gradient_convergence,\n",
    " rudy_intensity_symmetry_index,\n",
    " rudy_deviation_effect_index,\n",
    " demarcated_macro_proximity_index,\n",
    " macro_surface_irregularity_index,\n",
    " macro_rudy_boundary_interaction_index,\n",
    " pin_density_peak_contrast,\n",
    " rudy_pin_density_flux_index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.rudy_gradient_variability(images)>,\n",
       " <function __main__.clustered_macro_distance_std(images)>,\n",
       " <function __main__.rudy_pin_clustering_coefficient(images)>,\n",
       " <function __main__.macro_density_gradient(images)>,\n",
       " <function __main__.macro_aspect_ratio_variance(images)>,\n",
       " <function __main__.macro_compactness_index(images)>,\n",
       " <function __main__.rudy_pin_compaction_ratio(images)>,\n",
       " <function __main__.macro_variability_coefficient(images)>,\n",
       " <function __main__.macro_symmetry_coefficient(images)>,\n",
       " <function __main__.macro_cluster_density_contrast(images)>,\n",
       " <function __main__.rudy_pin_distribution_kurtosis(images)>,\n",
       " <function __main__.localized_rudy_variability_coefficient(images)>,\n",
       " <function __main__.macro_distribution_clarity_index(images)>,\n",
       " <function __main__.rudy_direction_consistency_index(images)>,\n",
       " <function __main__.rudy_pin_area_masking_index(images)>,\n",
       " <function __main__.rudy_pin_gradient_convergence(images)>,\n",
       " <function __main__.rudy_intensity_symmetry_index(images)>,\n",
       " <function __main__.rudy_deviation_effect_index(images)>,\n",
       " <function __main__.demarcated_macro_proximity_index(images)>,\n",
       " <function __main__.macro_surface_irregularity_index(images)>,\n",
       " <function __main__.macro_rudy_boundary_interaction_index(images)>,\n",
       " <function __main__.pin_density_peak_contrast(images)>,\n",
       " <function __main__.rudy_pin_density_flux_index(images)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[list(feat_pool.keys()) + [\"id\", \"label\", \"prediction_gpdl\"]]\n",
    "test_df_a = test_df_a[list(feat_pool.keys()) + [\"id\", \"label\", \"prediction_gpdl\"]]\n",
    "test_df_b = test_df_b[list(feat_pool.keys()) + [\"id\", \"label\", \"prediction_gpdl\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
